{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fera Formidável 4.2** - Stop right now, thank you very much\n",
        "Objetivo: implemente uma estratégia de Parada Antecipada (Early Stopping) no processo de treino da rede neural feita em Python puro ou no processo de treino da rede neural feita em PyTorch\n",
        "\n",
        "**Autores:**\n",
        "\n",
        "- Caio Matheus Leão Dantas\n",
        "- Rafael Anis Shaikhzadeh Santos\n",
        "\n",
        "\n",
        "**Contribuição:** Ambos discutiram o problema juntos, Caio Matheus realizou a primeira versão do código e Rafael Anis revisou o código e fez alterações para a versão final."
      ],
      "metadata": {
        "id": "R18n8AObqsP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INTRODUÇÃO**"
      ],
      "metadata": {
        "id": "SsLApC23Laod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo deste notebook é implementar uma estratégia de Parada Antecipada (Early Stopping) em uma rede neural MLP. Para isso, vamos treinar uma MLP com o dataset didático \"iris\", do seaborn. Os dados serão divididos em treino, validação e teste.\n",
        "\n",
        "Para o early stopping, enquanto otimizamos os parâmetros da nossa MLP com os dados de treino, vamos comparando a perda do teste com a perda de validação. Esperamos que, de início, as duas perdas diminuem ao passar das épocas. Mas, enquanto a perda do treino deve sempre diminuir, é esperado que em alguma época a perda da validação aumente, e é aí que aplicamos um early stopping, evitando um overfitting!"
      ],
      "metadata": {
        "id": "wbTBbcyILePt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "uNee12hsLd8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CÓDIGOS**"
      ],
      "metadata": {
        "id": "dm-JzsVhLhXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bibliotecas e funções importados das aulas de Redes Neurais"
      ],
      "metadata": {
        "id": "MolZHlbpfqjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliotecas importadas"
      ],
      "metadata": {
        "id": "SsmeP5TxfsrU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FiY1wZ9lgvfS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from graphviz import Digraph\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNÇÃO GRAFO"
      ],
      "metadata": {
        "id": "1WvV2UPv5mIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _tracar(folha):\n",
        "    \"\"\"Função modificada da criada por Andrej Karpathy para construção de grafo.\n",
        "\n",
        "    Referência: https://github.com/karpathy/micrograd\n",
        "\n",
        "    \"\"\"\n",
        "    vertices = set()\n",
        "    arestas = set()\n",
        "\n",
        "    def construir(v):\n",
        "        \"\"\"Função recursiva para traçar o grafo.\"\"\"\n",
        "        if v not in vertices:\n",
        "            vertices.add(v)\n",
        "            for progenitor in v.progenitor:\n",
        "                arestas.add((progenitor, v))\n",
        "                construir(progenitor)\n",
        "\n",
        "    construir(folha)\n",
        "\n",
        "    return vertices, arestas\n",
        "\n",
        "\n",
        "def plota_grafo(folha):\n",
        "    \"\"\"Função modificada da criada por Andrej Karpathy para construção de grafo.\n",
        "\n",
        "    Referência: https://github.com/karpathy/micrograd\n",
        "\n",
        "    \"\"\"\n",
        "    grafo = Digraph(format=\"svg\", graph_attr={\"rankdir\": \"LR\"})\n",
        "    vertices, arestas = _tracar(folha)\n",
        "\n",
        "    for v in vertices:\n",
        "        id_vertice = str(id(v))\n",
        "\n",
        "        if hasattr(v, \"rotulo\") and (hasattr(v, \"grad\")):\n",
        "            texto = \"{ \" + f\"{v.rotulo} | data {v.data:.3f} | grad {v.grad:.3f}\" + \" }\"\n",
        "\n",
        "        elif hasattr(v, \"rotulo\"):\n",
        "            texto = \"{ \" + f\"{v.rotulo} | data {v.data:.3f}\" + \" }\"\n",
        "\n",
        "        else:\n",
        "            texto = \"{ \" + f\"data {v.data:.3f}\" + \" }\"\n",
        "\n",
        "        grafo.node(name=id_vertice, label=texto, shape=\"record\")\n",
        "\n",
        "        if v.operador_mae:\n",
        "            grafo.node(name=id_vertice + v.operador_mae, label=v.operador_mae)\n",
        "            grafo.edge(id_vertice + v.operador_mae, id_vertice)\n",
        "\n",
        "    for vertice1, vertice2 in arestas:\n",
        "        grafo.edge(str(id(vertice1)), str(id(vertice2)) + vertice2.operador_mae)\n",
        "\n",
        "    return grafo"
      ],
      "metadata": {
        "id": "ykS2OtFUoYfm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASSE DA REDE NEURAL"
      ],
      "metadata": {
        "id": "p-KuktP-5oUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_dados_entrada, neuronios_c1, neuronios_c2, num_targets):\n",
        "        super().__init__()\n",
        "\n",
        "        self.camadas = nn.Sequential(\n",
        "            nn.Linear(num_dados_entrada, neuronios_c1),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(neuronios_c1, neuronios_c2),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(neuronios_c2, num_targets),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.camadas(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0DcBh571nKEU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tratando dataframe"
      ],
      "metadata": {
        "id": "adLBmemGf80P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando nosso df. Só analisaremos as plantas da espécie setosa aqui"
      ],
      "metadata": {
        "id": "wQ4bDi_K5vbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"iris\")\n",
        "df = df.dropna()\n",
        "df = df[df[\"species\"] == \"setosa\"]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JmxgEqqUneOV",
        "outputId": "2a50729f-797f-4a89-9dec-609feaa2e24e",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width species\n",
              "0            5.1          3.5           1.4          0.2  setosa\n",
              "1            4.9          3.0           1.4          0.2  setosa\n",
              "2            4.7          3.2           1.3          0.2  setosa\n",
              "3            4.6          3.1           1.5          0.2  setosa\n",
              "4            5.0          3.6           1.4          0.2  setosa\n",
              "5            5.4          3.9           1.7          0.4  setosa\n",
              "6            4.6          3.4           1.4          0.3  setosa\n",
              "7            5.0          3.4           1.5          0.2  setosa\n",
              "8            4.4          2.9           1.4          0.2  setosa\n",
              "9            4.9          3.1           1.5          0.1  setosa\n",
              "10           5.4          3.7           1.5          0.2  setosa\n",
              "11           4.8          3.4           1.6          0.2  setosa\n",
              "12           4.8          3.0           1.4          0.1  setosa\n",
              "13           4.3          3.0           1.1          0.1  setosa\n",
              "14           5.8          4.0           1.2          0.2  setosa\n",
              "15           5.7          4.4           1.5          0.4  setosa\n",
              "16           5.4          3.9           1.3          0.4  setosa\n",
              "17           5.1          3.5           1.4          0.3  setosa\n",
              "18           5.7          3.8           1.7          0.3  setosa\n",
              "19           5.1          3.8           1.5          0.3  setosa\n",
              "20           5.4          3.4           1.7          0.2  setosa\n",
              "21           5.1          3.7           1.5          0.4  setosa\n",
              "22           4.6          3.6           1.0          0.2  setosa\n",
              "23           5.1          3.3           1.7          0.5  setosa\n",
              "24           4.8          3.4           1.9          0.2  setosa\n",
              "25           5.0          3.0           1.6          0.2  setosa\n",
              "26           5.0          3.4           1.6          0.4  setosa\n",
              "27           5.2          3.5           1.5          0.2  setosa\n",
              "28           5.2          3.4           1.4          0.2  setosa\n",
              "29           4.7          3.2           1.6          0.2  setosa\n",
              "30           4.8          3.1           1.6          0.2  setosa\n",
              "31           5.4          3.4           1.5          0.4  setosa\n",
              "32           5.2          4.1           1.5          0.1  setosa\n",
              "33           5.5          4.2           1.4          0.2  setosa\n",
              "34           4.9          3.1           1.5          0.2  setosa\n",
              "35           5.0          3.2           1.2          0.2  setosa\n",
              "36           5.5          3.5           1.3          0.2  setosa\n",
              "37           4.9          3.6           1.4          0.1  setosa\n",
              "38           4.4          3.0           1.3          0.2  setosa\n",
              "39           5.1          3.4           1.5          0.2  setosa\n",
              "40           5.0          3.5           1.3          0.3  setosa\n",
              "41           4.5          2.3           1.3          0.3  setosa\n",
              "42           4.4          3.2           1.3          0.2  setosa\n",
              "43           5.0          3.5           1.6          0.6  setosa\n",
              "44           5.1          3.8           1.9          0.4  setosa\n",
              "45           4.8          3.0           1.4          0.3  setosa\n",
              "46           5.1          3.8           1.6          0.2  setosa\n",
              "47           4.6          3.2           1.4          0.2  setosa\n",
              "48           5.3          3.7           1.5          0.2  setosa\n",
              "49           5.0          3.3           1.4          0.2  setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c024ccb-1efd-4570-a2b5-6711c9babc30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5.2</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>5.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c024ccb-1efd-4570-a2b5-6711c9babc30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c024ccb-1efd-4570-a2b5-6711c9babc30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c024ccb-1efd-4570-a2b5-6711c9babc30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2dc80aff-fee5-42ea-b5e2-0db3d0fc6fbf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2dc80aff-fee5-42ea-b5e2-0db3d0fc6fbf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2dc80aff-fee5-42ea-b5e2-0db3d0fc6fbf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ec57921b-3609-4b7e-915f-1c185d9d6b32\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ec57921b-3609-4b7e-915f-1c185d9d6b32 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3524896872134512,\n        \"min\": 4.3,\n        \"max\": 5.8,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          5.8,\n          5.2,\n          5.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3790643690962886,\n        \"min\": 2.3,\n        \"max\": 4.4,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          3.5,\n          3.0,\n          3.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1736639964801841,\n        \"min\": 1.0,\n        \"max\": 1.9,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.0,\n          1.3,\n          1.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10538558938004569,\n        \"min\": 0.1,\n        \"max\": 0.6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.2,\n          0.4,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"setosa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINIÇÃO DOS ATRIBUTOS E TARGET"
      ],
      "metadata": {
        "id": "NzKZhnvc5yEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = [\n",
        "    \"sepal_length\",\n",
        "    \"sepal_width\",\n",
        "    \"petal_length\"\n",
        "]\n",
        "y = [\"petal_width\"]\n",
        "\n",
        "df = df.reindex(X + y, axis=1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SqEpaDH2pkgU",
        "outputId": "db6f0469-fc29-4dbf-d6a5-1710da1f98a5",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width\n",
              "0            5.1          3.5           1.4          0.2\n",
              "1            4.9          3.0           1.4          0.2\n",
              "2            4.7          3.2           1.3          0.2\n",
              "3            4.6          3.1           1.5          0.2\n",
              "4            5.0          3.6           1.4          0.2\n",
              "5            5.4          3.9           1.7          0.4\n",
              "6            4.6          3.4           1.4          0.3\n",
              "7            5.0          3.4           1.5          0.2\n",
              "8            4.4          2.9           1.4          0.2\n",
              "9            4.9          3.1           1.5          0.1\n",
              "10           5.4          3.7           1.5          0.2\n",
              "11           4.8          3.4           1.6          0.2\n",
              "12           4.8          3.0           1.4          0.1\n",
              "13           4.3          3.0           1.1          0.1\n",
              "14           5.8          4.0           1.2          0.2\n",
              "15           5.7          4.4           1.5          0.4\n",
              "16           5.4          3.9           1.3          0.4\n",
              "17           5.1          3.5           1.4          0.3\n",
              "18           5.7          3.8           1.7          0.3\n",
              "19           5.1          3.8           1.5          0.3\n",
              "20           5.4          3.4           1.7          0.2\n",
              "21           5.1          3.7           1.5          0.4\n",
              "22           4.6          3.6           1.0          0.2\n",
              "23           5.1          3.3           1.7          0.5\n",
              "24           4.8          3.4           1.9          0.2\n",
              "25           5.0          3.0           1.6          0.2\n",
              "26           5.0          3.4           1.6          0.4\n",
              "27           5.2          3.5           1.5          0.2\n",
              "28           5.2          3.4           1.4          0.2\n",
              "29           4.7          3.2           1.6          0.2\n",
              "30           4.8          3.1           1.6          0.2\n",
              "31           5.4          3.4           1.5          0.4\n",
              "32           5.2          4.1           1.5          0.1\n",
              "33           5.5          4.2           1.4          0.2\n",
              "34           4.9          3.1           1.5          0.2\n",
              "35           5.0          3.2           1.2          0.2\n",
              "36           5.5          3.5           1.3          0.2\n",
              "37           4.9          3.6           1.4          0.1\n",
              "38           4.4          3.0           1.3          0.2\n",
              "39           5.1          3.4           1.5          0.2\n",
              "40           5.0          3.5           1.3          0.3\n",
              "41           4.5          2.3           1.3          0.3\n",
              "42           4.4          3.2           1.3          0.2\n",
              "43           5.0          3.5           1.6          0.6\n",
              "44           5.1          3.8           1.9          0.4\n",
              "45           4.8          3.0           1.4          0.3\n",
              "46           5.1          3.8           1.6          0.2\n",
              "47           4.6          3.2           1.4          0.2\n",
              "48           5.3          3.7           1.5          0.2\n",
              "49           5.0          3.3           1.4          0.2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c87392c-ae6c-4739-be62-62d2e2eff953\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5.2</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>5.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c87392c-ae6c-4739-be62-62d2e2eff953')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c87392c-ae6c-4739-be62-62d2e2eff953 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c87392c-ae6c-4739-be62-62d2e2eff953');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e639cb31-7659-4b86-8507-efc01c1483d1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e639cb31-7659-4b86-8507-efc01c1483d1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e639cb31-7659-4b86-8507-efc01c1483d1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b27769e4-fd08-4031-8718-5582873d5913\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b27769e4-fd08-4031-8718-5582873d5913 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3524896872134512,\n        \"min\": 4.3,\n        \"max\": 5.8,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          5.8,\n          5.2,\n          5.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3790643690962886,\n        \"min\": 2.3,\n        \"max\": 4.4,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          3.5,\n          3.0,\n          3.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1736639964801841,\n        \"min\": 1.0,\n        \"max\": 1.9,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.0,\n          1.3,\n          1.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10538558938004569,\n        \"min\": 0.1,\n        \"max\": 0.6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.2,\n          0.4,\n          0.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split de dados"
      ],
      "metadata": {
        "id": "iq7EdHcKg6JX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos fazer isso em dois passos, primeiro dividir em teste e treino/validação, e depois dividir o treino/validação em treino e validação."
      ],
      "metadata": {
        "id": "dA2pOxMLhF6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAMANHO_TESTE = 0.1\n",
        "TAMANHO_VALIDACAO = 0.1\n",
        "TAMANHO_TREINO = 1 - TAMANHO_TESTE - TAMANHO_VALIDACAO\n",
        "TAMANHO_TREINO, TAMANHO_VALIDACAO, TAMANHO_TESTE\n",
        "SEMENTE_ALEATORIA = 8"
      ],
      "metadata": {
        "id": "tEDxq0FwgYkf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = df.index\n",
        "indices_treino_val, indices_teste = train_test_split(\n",
        "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
        ")\n",
        "\n",
        "df_treino_val = df.loc[indices_treino_val]\n",
        "df_teste = df.loc[indices_teste]\n",
        "\n",
        "X_teste = df_teste.reindex(X, axis=1).values\n",
        "y_teste = df_teste.reindex(y, axis=1).values"
      ],
      "metadata": {
        "id": "O-1r_HcO2z-e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_treino_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "2IQMhzKk4Ztd",
        "outputId": "b967c85e-82b9-47d4-cdce-c30928a3d2e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width\n",
              "22           4.6          3.6           1.0          0.2\n",
              "33           5.5          4.2           1.4          0.2\n",
              "0            5.1          3.5           1.4          0.2\n",
              "17           5.1          3.5           1.4          0.3\n",
              "45           4.8          3.0           1.4          0.3\n",
              "39           5.1          3.4           1.5          0.2\n",
              "38           4.4          3.0           1.3          0.2\n",
              "16           5.4          3.9           1.3          0.4\n",
              "12           4.8          3.0           1.4          0.1\n",
              "11           4.8          3.4           1.6          0.2\n",
              "1            4.9          3.0           1.4          0.2\n",
              "32           5.2          4.1           1.5          0.1\n",
              "46           5.1          3.8           1.6          0.2\n",
              "30           4.8          3.1           1.6          0.2\n",
              "31           5.4          3.4           1.5          0.4\n",
              "2            4.7          3.2           1.3          0.2\n",
              "28           5.2          3.4           1.4          0.2\n",
              "42           4.4          3.2           1.3          0.2\n",
              "7            5.0          3.4           1.5          0.2\n",
              "25           5.0          3.0           1.6          0.2\n",
              "47           4.6          3.2           1.4          0.2\n",
              "4            5.0          3.6           1.4          0.2\n",
              "43           5.0          3.5           1.6          0.6\n",
              "37           4.9          3.6           1.4          0.1\n",
              "24           4.8          3.4           1.9          0.2\n",
              "35           5.0          3.2           1.2          0.2\n",
              "6            4.6          3.4           1.4          0.3\n",
              "14           5.8          4.0           1.2          0.2\n",
              "18           5.7          3.8           1.7          0.3\n",
              "34           4.9          3.1           1.5          0.2\n",
              "29           4.7          3.2           1.6          0.2\n",
              "15           5.7          4.4           1.5          0.4\n",
              "9            4.9          3.1           1.5          0.1\n",
              "13           4.3          3.0           1.1          0.1\n",
              "27           5.2          3.5           1.5          0.2\n",
              "10           5.4          3.7           1.5          0.2\n",
              "21           5.1          3.7           1.5          0.4\n",
              "40           5.0          3.5           1.3          0.3\n",
              "19           5.1          3.8           1.5          0.3\n",
              "8            4.4          2.9           1.4          0.2\n",
              "26           5.0          3.4           1.6          0.4\n",
              "5            5.4          3.9           1.7          0.4\n",
              "41           4.5          2.3           1.3          0.3\n",
              "20           5.4          3.4           1.7          0.2\n",
              "3            4.6          3.1           1.5          0.2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4b72dbf-58f1-45c4-8c2c-d55ccc37471f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5.2</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4b72dbf-58f1-45c4-8c2c-d55ccc37471f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4b72dbf-58f1-45c4-8c2c-d55ccc37471f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4b72dbf-58f1-45c4-8c2c-d55ccc37471f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fb8ccd06-b42f-41c6-b366-003a118760f7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb8ccd06-b42f-41c6-b366-003a118760f7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fb8ccd06-b42f-41c6-b366-003a118760f7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1f1decad-357e-4b58-b5f6-fe40a65e0ae1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_treino_val')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1f1decad-357e-4b58-b5f6-fe40a65e0ae1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_treino_val');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_treino_val",
              "summary": "{\n  \"name\": \"df_treino_val\",\n  \"rows\": 45,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3605271112964987,\n        \"min\": 4.3,\n        \"max\": 5.8,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          5.0,\n          5.7,\n          4.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.39271137266728373,\n        \"min\": 2.3,\n        \"max\": 4.4,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          3.2,\n          4.4,\n          3.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16462384426628512,\n        \"min\": 1.0,\n        \"max\": 1.9,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.7,\n          1.4,\n          1.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10090499582190258,\n        \"min\": 0.1,\n        \"max\": 0.6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3,\n          0.6,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_teste"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_J1y5YPO44SL",
        "outputId": "5410b49f-f32c-4413-c29f-5c4fca768df3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width\n",
              "44           5.1          3.8           1.9          0.4\n",
              "49           5.0          3.3           1.4          0.2\n",
              "36           5.5          3.5           1.3          0.2\n",
              "23           5.1          3.3           1.7          0.5\n",
              "48           5.3          3.7           1.5          0.2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7d16ba9-73b1-428d-84f0-4ece6bed5231\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>5.3</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7d16ba9-73b1-428d-84f0-4ece6bed5231')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7d16ba9-73b1-428d-84f0-4ece6bed5231 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7d16ba9-73b1-428d-84f0-4ece6bed5231');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c2abedf0-b2da-4d68-9284-d987dc74ae3b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2abedf0-b2da-4d68-9284-d987dc74ae3b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c2abedf0-b2da-4d68-9284-d987dc74ae3b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4b6d0269-c9bd-4325-80dc-d6a21e75aef2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_teste')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4b6d0269-c9bd-4325-80dc-d6a21e75aef2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_teste');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_teste",
              "summary": "{\n  \"name\": \"df_teste\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20000000000000007,\n        \"min\": 5.0,\n        \"max\": 5.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5.0,\n          5.3,\n          5.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22803508501982767,\n        \"min\": 3.3,\n        \"max\": 3.8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3.3,\n          3.7,\n          3.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24083189157584586,\n        \"min\": 1.3,\n        \"max\": 1.9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.4,\n          1.5,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1414213562373095,\n        \"min\": 0.2,\n        \"max\": 0.5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4,\n          0.2,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINIÇÃO DOS DATAFRAMES DE TREINO E VALIDAÇÃO"
      ],
      "metadata": {
        "id": "cDMsiNP56G9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = df_treino_val.index\n",
        "indices_treino, indices_val = train_test_split(\n",
        "    indices, test_size=TAMANHO_TESTE, random_state=SEMENTE_ALEATORIA\n",
        ")\n",
        "\n",
        "df_treino = df.loc[indices_treino]\n",
        "df_val = df.loc[indices_val]\n",
        "\n",
        "X_treino = df_treino.reindex(X, axis=1).values\n",
        "y_treino = df_treino.reindex(y, axis=1).values\n",
        "\n",
        "X_val = df_val.reindex(X, axis=1).values\n",
        "y_val = df_val.reindex(y, axis=1).values"
      ],
      "metadata": {
        "id": "dWuW0UGN4xZs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_treino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "ulbRgvb441r9",
        "outputId": "19339f4f-bbd6-4358-c30b-4c220110d12e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width\n",
              "37           4.9          3.6           1.4          0.1\n",
              "9            4.9          3.1           1.5          0.1\n",
              "22           4.6          3.6           1.0          0.2\n",
              "15           5.7          4.4           1.5          0.4\n",
              "43           5.0          3.5           1.6          0.6\n",
              "28           5.2          3.4           1.4          0.2\n",
              "32           5.2          4.1           1.5          0.1\n",
              "33           5.5          4.2           1.4          0.2\n",
              "27           5.2          3.5           1.5          0.2\n",
              "41           4.5          2.3           1.3          0.3\n",
              "18           5.7          3.8           1.7          0.3\n",
              "26           5.0          3.4           1.6          0.4\n",
              "29           4.7          3.2           1.6          0.2\n",
              "35           5.0          3.2           1.2          0.2\n",
              "21           5.1          3.7           1.5          0.4\n",
              "16           5.4          3.9           1.3          0.4\n",
              "40           5.0          3.5           1.3          0.3\n",
              "45           4.8          3.0           1.4          0.3\n",
              "19           5.1          3.8           1.5          0.3\n",
              "13           4.3          3.0           1.1          0.1\n",
              "24           4.8          3.4           1.9          0.2\n",
              "38           4.4          3.0           1.3          0.2\n",
              "31           5.4          3.4           1.5          0.4\n",
              "7            5.0          3.4           1.5          0.2\n",
              "10           5.4          3.7           1.5          0.2\n",
              "0            5.1          3.5           1.4          0.2\n",
              "34           4.9          3.1           1.5          0.2\n",
              "2            4.7          3.2           1.3          0.2\n",
              "11           4.8          3.4           1.6          0.2\n",
              "30           4.8          3.1           1.6          0.2\n",
              "14           5.8          4.0           1.2          0.2\n",
              "1            4.9          3.0           1.4          0.2\n",
              "4            5.0          3.6           1.4          0.2\n",
              "25           5.0          3.0           1.6          0.2\n",
              "12           4.8          3.0           1.4          0.1\n",
              "6            4.6          3.4           1.4          0.3\n",
              "39           5.1          3.4           1.5          0.2\n",
              "5            5.4          3.9           1.7          0.4\n",
              "47           4.6          3.2           1.4          0.2\n",
              "17           5.1          3.5           1.4          0.3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc290a4f-1280-4865-b501-d00b57af5f75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5.2</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>5.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5.8</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc290a4f-1280-4865-b501-d00b57af5f75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc290a4f-1280-4865-b501-d00b57af5f75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc290a4f-1280-4865-b501-d00b57af5f75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-db86b054-e412-4f3b-af26-0aee7abddf62\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db86b054-e412-4f3b-af26-0aee7abddf62')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-db86b054-e412-4f3b-af26-0aee7abddf62 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b05dc441-7e05-40ae-9a87-151026ade227\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_treino')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b05dc441-7e05-40ae-9a87-151026ade227 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_treino');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_treino",
              "summary": "{\n  \"name\": \"df_treino\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34626209133752417,\n        \"min\": 4.3,\n        \"max\": 5.8,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          5.4,\n          4.3,\n          4.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3990694303707191,\n        \"min\": 2.3,\n        \"max\": 4.4,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          3.2,\n          3.9,\n          3.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.166332999331662,\n        \"min\": 1.0,\n        \"max\": 1.9,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.1,\n          1.5,\n          1.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10609623111312795,\n        \"min\": 0.1,\n        \"max\": 0.6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2,\n          0.3,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "0pOieEFB4s4d",
        "outputId": "d76079a9-ec4e-4a4e-a6dc-a42ab060c717"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    sepal_length  sepal_width  petal_length  petal_width\n",
              "8            4.4          2.9           1.4          0.2\n",
              "3            4.6          3.1           1.5          0.2\n",
              "46           5.1          3.8           1.6          0.2\n",
              "20           5.4          3.4           1.7          0.2\n",
              "42           4.4          3.2           1.3          0.2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bed6ed1-9ab0-4217-b499-01f39a088d57\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bed6ed1-9ab0-4217-b499-01f39a088d57')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bed6ed1-9ab0-4217-b499-01f39a088d57 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bed6ed1-9ab0-4217-b499-01f39a088d57');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bdade459-85f1-466f-9556-966f5c29ab74\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bdade459-85f1-466f-9556-966f5c29ab74')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bdade459-85f1-466f-9556-966f5c29ab74 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1759c711-787d-4368-bf8d-c64a46b0e9f8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_val')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1759c711-787d-4368-bf8d-c64a46b0e9f8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_val');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_val",
              "summary": "{\n  \"name\": \"df_val\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4494441010848846,\n        \"min\": 4.4,\n        \"max\": 5.4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.6,\n          5.4,\n          4.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3420526275297413,\n        \"min\": 2.9,\n        \"max\": 3.8,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.1,\n          3.2,\n          3.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15811388300841897,\n        \"min\": 1.3,\n        \"max\": 1.7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.5,\n          1.3,\n          1.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.2,\n        \"max\": 0.2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalização e transformação dos vetores em tensores"
      ],
      "metadata": {
        "id": "jDZQZfUQ6MDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_scaler = StandardScaler()\n",
        "x_scaler.fit(X_treino)\n",
        "\n",
        "y_scaler = StandardScaler()\n",
        "y_scaler.fit(y_treino)\n",
        "\n",
        "X_treino = x_scaler.transform(X_treino)\n",
        "y_treino = y_scaler.transform(y_treino)\n",
        "\n",
        "X_val = x_scaler.transform(X_val)\n",
        "y_val = y_scaler.transform(y_val)\n",
        "\n",
        "X_teste = x_scaler.transform(X_teste)\n",
        "y_teste = y_scaler.transform(y_teste)"
      ],
      "metadata": {
        "id": "qz5pJe7Y5R2Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_treino = torch.tensor(X_treino, dtype=torch.float32)\n",
        "y_treino = torch.tensor(y_treino, dtype=torch.float32)\n",
        "\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "X_teste = torch.tensor(X_teste, dtype=torch.float32)\n",
        "y_teste = torch.tensor(y_teste, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "KVrHqQl85cOz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trabalhando com a MLP"
      ],
      "metadata": {
        "id": "jNOAv8rkhZ_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos finalmente definir nossa MLP e usá-la"
      ],
      "metadata": {
        "id": "_U4WUuCdhhJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINIÇÃO DA MLP"
      ],
      "metadata": {
        "id": "toDj0mp3MAq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_DADOS_DE_ENTRADA = 3\n",
        "NUM_DADOS_DE_SAIDA = 1\n",
        "NEURONIOS_C1 = 3\n",
        "NEURONIOS_C2 = 2\n",
        "\n",
        "minha_mlp = MLP(\n",
        "    NUM_DADOS_DE_ENTRADA, NEURONIOS_C1, NEURONIOS_C2, NUM_DADOS_DE_SAIDA\n",
        ")"
      ],
      "metadata": {
        "id": "BJOIQRVhsVZ7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREVISÃO COM A MLP"
      ],
      "metadata": {
        "id": "8CscXXOdMC0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prev = minha_mlp(X_treino)\n",
        "y_prev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVelgdLns0JS",
        "outputId": "244aebec-0d56-480e-fc38-e27f41fcc98a",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1721],\n",
              "        [0.1755],\n",
              "        [0.1811],\n",
              "        [0.1587],\n",
              "        [0.1689],\n",
              "        [0.1698],\n",
              "        [0.1636],\n",
              "        [0.1618],\n",
              "        [0.1675],\n",
              "        [0.1863],\n",
              "        [0.1559],\n",
              "        [0.1698],\n",
              "        [0.1758],\n",
              "        [0.1775],\n",
              "        [0.1672],\n",
              "        [0.1650],\n",
              "        [0.1732],\n",
              "        [0.1791],\n",
              "        [0.1665],\n",
              "        [0.1892],\n",
              "        [0.1683],\n",
              "        [0.1853],\n",
              "        [0.1654],\n",
              "        [0.1712],\n",
              "        [0.1632],\n",
              "        [0.1703],\n",
              "        [0.1755],\n",
              "        [0.1801],\n",
              "        [0.1726],\n",
              "        [0.1754],\n",
              "        [0.1615],\n",
              "        [0.1778],\n",
              "        [0.1708],\n",
              "        [0.1736],\n",
              "        [0.1791],\n",
              "        [0.1781],\n",
              "        [0.1698],\n",
              "        [0.1593],\n",
              "        [0.1800],\n",
              "        [0.1703]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIMIZADOR COM DESCIDA DO GRADIENTE ESTOCÁSTICO\n",
        "\n",
        "Podemos agora buscar otimizá-la, definindo uma taxa de aprendizado, o otimizador de descida do gradiente estocástico do torch e a função de perda, que aqui será de MSE."
      ],
      "metadata": {
        "id": "1Ec48OZ6MFbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAXA_DE_APRENDIZADO = 0.001\n",
        "\n",
        "otimizador = optim.SGD(minha_mlp.parameters(), lr=TAXA_DE_APRENDIZADO)\n",
        "fn_perda = nn.MSELoss()"
      ],
      "metadata": {
        "id": "uBuK04P5s5zD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfeito, podemos seguir pra melhor parte. Vamos treinar nossa MLP com um Early Stopping! Esse treino será feito com loops em épocas, exatamente como sempre vimos. Calculamos a perda do treino e usamos essa para otimizar os parâmetros.\n",
        "\n",
        "Mas aqui, teremos um passo a mais, para cada época também vamos analisar a perda da validação, nos mantendo alerta para se sua perda também está diminuindo. Se em alguma época a perda subir, está na hora de parar nosso treino, evitando um overfitting.\n",
        "\n",
        "Porém, ao invés de parar instantaneamente, vamos ser pacientes! Vamos rodar mais algumas épocas, e ver se perda cai de novo e alcança um novo melhor valor de perda. Se mesmo, depois de sermos pacientes nada melhora, aí sim! Paramos o nosso código, tendo guardado os parâmetros da melhor época."
      ],
      "metadata": {
        "id": "PxW-GSYWiaBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFININDO O VALOR DE PACIÊNCIA"
      ],
      "metadata": {
        "id": "sqsjw6WfMaFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 30\n",
        "melhor_val_loss = float('inf')\n",
        "contador_paciencia = 0\n",
        "melhores_pesos = None"
      ],
      "metadata": {
        "id": "BqwP88YqKMn4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCAS = 10000\n",
        "\n",
        "minha_mlp.train()\n",
        "\n",
        "for epoca in range(N_EPOCAS):\n",
        "    minha_mlp = minha_mlp.double()\n",
        "    X_treino = X_treino.double()\n",
        "    y_treino = y_treino.double()\n",
        "    y_pred = minha_mlp(X_treino)\n",
        "    otimizador.zero_grad()\n",
        "    loss_treino = fn_perda(y_treino, y_pred)\n",
        "    loss_treino.backward()\n",
        "    otimizador.step()\n",
        "\n",
        "    #Validação\n",
        "    minha_mlp.eval()\n",
        "    with torch.no_grad():\n",
        "      X_val = X_val.double()\n",
        "      y_val = y_val.double()\n",
        "      y_val_pred = minha_mlp(X_val)\n",
        "      loss_val = fn_perda(y_val, y_val_pred)\n",
        "\n",
        "    print(epoca, \"- Perda do treino: \", loss_treino.item(), \"/ Perda da validação: \", loss_val.item())\n",
        "\n",
        "\n",
        "    #Early Stopping\n",
        "    if loss_val.item() < melhor_val_loss - 1e-3:\n",
        "        melhor_val_loss = loss_val.item()\n",
        "        contador_paciencia = 0\n",
        "        melhores_pesos = copy.deepcopy(minha_mlp.state_dict())\n",
        "    else:\n",
        "        contador_paciencia += 1\n",
        "        if contador_paciencia >= patience:\n",
        "            print(f\"Pausa na época {epoca} pois val_loss não melhorou por {patience} épocas, o melhor valor de perda seria de {melhor_val_loss}, na epoca {epoca-30}\")\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dkIsNeWwcsj",
        "outputId": "d9219422-2527-4787-9e88-6447891585f1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - Perda do treino:  1.035123170711169 / Perda da validação:  0.36500854446780845\n",
            "1 - Perda do treino:  1.0349405032379142 / Perda da validação:  0.3643621486867529\n",
            "2 - Perda do treino:  1.0347589838180071 / Perda da validação:  0.3637183553053339\n",
            "3 - Perda do treino:  1.0345786052507906 / Perda da validação:  0.36307715267701074\n",
            "4 - Perda do treino:  1.0343993603802735 / Perda da validação:  0.3624385292128413\n",
            "5 - Perda do treino:  1.0342212420948562 / Perda da validação:  0.36180247338117677\n",
            "6 - Perda do treino:  1.034044243327061 / Perda da validação:  0.36116897370735546\n",
            "7 - Perda do treino:  1.0338683570532625 / Perda da validação:  0.36053801877339914\n",
            "8 - Perda do treino:  1.0336935762934185 / Perda da validação:  0.3599095972177123\n",
            "9 - Perda do treino:  1.0335198941108057 / Perda da validação:  0.3592836977347807\n",
            "10 - Perda do treino:  1.0333473036117522 / Perda da validação:  0.3586603090748739\n",
            "11 - Perda do treino:  1.033175797945378 / Perda da validação:  0.3580394200437474\n",
            "12 - Perda do treino:  1.03300537030333 / Perda da validação:  0.3574210195023487\n",
            "13 - Perda do treino:  1.0328360139195245 / Perda da validação:  0.35680509636652263\n",
            "14 - Perda do treino:  1.0326677220698879 / Perda da validação:  0.35619163960672007\n",
            "15 - Perda do treino:  1.0325004880720994 / Perda da validação:  0.3555806382477074\n",
            "16 - Perda do treino:  1.0323343052853367 / Perda da validação:  0.35497208136827807\n",
            "17 - Perda do treino:  1.032169167110021 / Perda da validação:  0.35436595810096516\n",
            "18 - Perda do treino:  1.0320050669875667 / Perda da validação:  0.353762257631756\n",
            "19 - Perda do treino:  1.0318419984001277 / Perda da validação:  0.3531609691998087\n",
            "20 - Perda do treino:  1.031679954870351 / Perda da validação:  0.3525620820971693\n",
            "21 - Perda do treino:  1.0315189299611274 / Perda da validação:  0.35196558566849095\n",
            "22 - Perda do treino:  1.0313589172753452 / Perda da validação:  0.3513714693107553\n",
            "23 - Perda do treino:  1.0311999104556466 / Perda da validação:  0.3507797224729944\n",
            "24 - Perda do treino:  1.0310419031841829 / Perda da validação:  0.35019033465601446\n",
            "25 - Perda do treino:  1.0308848891823732 / Perda da validação:  0.3496032954121218\n",
            "26 - Perda do treino:  1.030728862210665 / Perda da validação:  0.34901859434484933\n",
            "27 - Perda do treino:  1.0305738160682931 / Perda da validação:  0.3484362211086854\n",
            "28 - Perda do treino:  1.0304197445930434 / Perda da validação:  0.34785616540880304\n",
            "29 - Perda do treino:  1.0302666416610178 / Perda da validação:  0.3472784170007925\n",
            "30 - Perda do treino:  1.0301145011863968 / Perda da validação:  0.3467029656903934\n",
            "31 - Perda do treino:  1.0299633171212084 / Perda da validação:  0.3461298013332291\n",
            "32 - Perda do treino:  1.0298130834550956 / Perda da validação:  0.34555891383454335\n",
            "33 - Perda do treino:  1.029663794215086 / Perda da validação:  0.3449902931489371\n",
            "34 - Perda do treino:  1.0295154434653617 / Perda da validação:  0.3444239292801073\n",
            "35 - Perda do treino:  1.0293680253070328 / Perda da validação:  0.34385981228058726\n",
            "36 - Perda do treino:  1.0292215338779107 / Perda da validação:  0.3432979322514885\n",
            "37 - Perda do treino:  1.029075963352283 / Perda da validação:  0.34273827934224405\n",
            "38 - Perda do treino:  1.0289313079406892 / Perda da validação:  0.34218084375035224\n",
            "39 - Perda do treino:  1.0287875618897 / Perda da validação:  0.3416256157211238\n",
            "40 - Perda do treino:  1.0286447194816941 / Perda da validação:  0.34107258554742814\n",
            "41 - Perda do treino:  1.0285027750346405 / Perda da validação:  0.3405217435694433\n",
            "42 - Perda do treino:  1.028361722901879 / Perda da validação:  0.3399730801744045\n",
            "43 - Perda do treino:  1.0282215574719042 / Perda da validação:  0.3394265857963578\n",
            "44 - Perda do treino:  1.0280822731681485 / Perda da validação:  0.3388822509159112\n",
            "45 - Perda do treino:  1.027943864448768 / Perda da validação:  0.33834006605999006\n",
            "46 - Perda do treino:  1.0278063258064307 / Perda da validação:  0.33780002180159224\n",
            "47 - Perda do treino:  1.027669651768103 / Perda da validação:  0.33726210875954515\n",
            "48 - Perda do treino:  1.02753383689484 / Perda da validação:  0.3367263175982647\n",
            "49 - Perda do treino:  1.0273988757815755 / Perda da validação:  0.33619263902751395\n",
            "50 - Perda do treino:  1.0272647630569154 / Perda da validação:  0.3356610638021653\n",
            "51 - Perda do treino:  1.027131493382929 / Perda da validação:  0.3351315827219619\n",
            "52 - Perda do treino:  1.0269990614549442 / Perda da validação:  0.33460418663128166\n",
            "53 - Perda do treino:  1.0268674620013445 / Perda da validação:  0.3340788664189026\n",
            "54 - Perda do treino:  1.0267366897833639 / Perda da validação:  0.3335556130177685\n",
            "55 - Perda do treino:  1.026606739594886 / Perda da validação:  0.33303441740475714\n",
            "56 - Perda do treino:  1.0264776062622434 / Perda da validação:  0.33251527060044844\n",
            "57 - Perda do treino:  1.0263492846440179 / Perda da validação:  0.3319981636688948\n",
            "58 - Perda do treino:  1.026221769630843 / Perda da validação:  0.33148308771739327\n",
            "59 - Perda do treino:  1.026095056145206 / Perda da validação:  0.33097003389625695\n",
            "60 - Perda do treino:  1.0259691391412527 / Perda da validação:  0.33045899339859\n",
            "61 - Perda do treino:  1.025844013604592 / Perda da validação:  0.32994995746006206\n",
            "62 - Perda do treino:  1.0257196745521042 / Perda da validação:  0.3294429173586852\n",
            "63 - Perda do treino:  1.0255961170317458 / Perda da validação:  0.3289378644145912\n",
            "64 - Perda do treino:  1.0254733361223616 / Perda da validação:  0.3284347899898109\n",
            "65 - Perda do treino:  1.0253513269334913 / Perda da validação:  0.32793368548805335\n",
            "66 - Perda do treino:  1.0252300846051843 / Perda da validação:  0.3274345423544882\n",
            "67 - Perda do treino:  1.0251096043078083 / Perda da validação:  0.32693735207552815\n",
            "68 - Perda do treino:  1.0249898812418656 / Perda da validação:  0.32644210617861147\n",
            "69 - Perda do treino:  1.0248709106378062 / Perda da validação:  0.3259487962319884\n",
            "70 - Perda do treino:  1.0247526877558435 / Perda da validação:  0.3254574138445063\n",
            "71 - Perda do treino:  1.0246352078857714 / Perda da validação:  0.32496795066539763\n",
            "72 - Perda do treino:  1.0245184663467823 / Perda da validação:  0.3244803983840675\n",
            "73 - Perda do treino:  1.0244024584872855 / Perda da validação:  0.32399474872988465\n",
            "74 - Perda do treino:  1.0242871796847282 / Perda da validação:  0.32351099347197065\n",
            "75 - Perda do treino:  1.0241726253454153 / Perda da validação:  0.32302912441899284\n",
            "76 - Perda do treino:  1.024058790904333 / Perda da validação:  0.3225491334189577\n",
            "77 - Perda do treino:  1.023945671824971 / Perda da validação:  0.3220710123590039\n",
            "78 - Perda do treino:  1.023833263599148 / Perda da validação:  0.321594753165199\n",
            "79 - Perda do treino:  1.0237215617468363 / Perda da validação:  0.3211203478023349\n",
            "80 - Perda do treino:  1.023610561815988 / Perda da validação:  0.32064778827372614\n",
            "81 - Perda do treino:  1.0235002593823637 / Perda da validação:  0.3201770666210083\n",
            "82 - Perda do treino:  1.0233906500493604 / Perda da validação:  0.3197081749239379\n",
            "83 - Perda do treino:  1.0232817294478405 / Perda da validação:  0.31924110530019345\n",
            "84 - Perda do treino:  1.023173493235964 / Perda da validação:  0.3187758499051774\n",
            "85 - Perda do treino:  1.0230659370990187 / Perda da validação:  0.3183124009318193\n",
            "86 - Perda do treino:  1.022959056749254 / Perda da validação:  0.31785075061038004\n",
            "87 - Perda do treino:  1.0228528479257135 / Perda da validação:  0.3173908912082571\n",
            "88 - Perda do treino:  1.0227473063940706 / Perda da validação:  0.3169328150297913\n",
            "89 - Perda do treino:  1.0226424279464645 / Perda da validação:  0.3164765144160734\n",
            "90 - Perda do treino:  1.0225382084013355 / Perda da validação:  0.31602198174475365\n",
            "91 - Perda do treino:  1.0224346436032636 / Perda da validação:  0.31556920942985023\n",
            "92 - Perda do treino:  1.022331729422808 / Perda da validação:  0.31511818992156093\n",
            "93 - Perda do treino:  1.0222294617563452 / Perda da validação:  0.3146689157060741\n",
            "94 - Perda do treino:  1.0221278365259105 / Perda da validação:  0.3142213793053813\n",
            "95 - Perda do treino:  1.0220268496790395 / Perda da validação:  0.3137755732770918\n",
            "96 - Perda do treino:  1.0219264971886102 / Perda da validação:  0.31333149021424644\n",
            "97 - Perda do treino:  1.0218267750526873 / Perda da validação:  0.31288912274513353\n",
            "98 - Perda do treino:  1.0217276792943668 / Perda da validação:  0.31244846353310646\n",
            "99 - Perda do treino:  1.02162920596162 / Perda da validação:  0.3120095052764003\n",
            "100 - Perda do treino:  1.021531351127141 / Perda da validação:  0.31157224070795103\n",
            "101 - Perda do treino:  1.0214341108881944 / Perda da validação:  0.3111366625952158\n",
            "102 - Perda do treino:  1.021337481366461 / Perda da validação:  0.31070276373999306\n",
            "103 - Perda do treino:  1.021241458707891 / Perda da validação:  0.3102705369782447\n",
            "104 - Perda do treino:  1.0211460390825504 / Perda da validação:  0.3098399751799188\n",
            "105 - Perda do treino:  1.0210512186844736 / Perda da validação:  0.3094110712487727\n",
            "106 - Perda do treino:  1.0209569937315148 / Perda da validação:  0.30898381812219883\n",
            "107 - Perda do treino:  1.0208633604652018 / Perda da validação:  0.308558208771049\n",
            "108 - Perda do treino:  1.0207703151505876 / Perda da validação:  0.30813423619946223\n",
            "109 - Perda do treino:  1.020677854076107 / Perda da validação:  0.3077118934446917\n",
            "110 - Perda do treino:  1.0205859735534308 / Perda da validação:  0.307291173576933\n",
            "111 - Perda do treino:  1.0204946699173223 / Perda da validação:  0.30687206969915426\n",
            "112 - Perda do treino:  1.0204039395254951 / Perda da validação:  0.306454574946926\n",
            "113 - Perda do treino:  1.0203137787584706 / Perda da validação:  0.3060386824882525\n",
            "114 - Perda do treino:  1.0202241840194364 / Perda da validação:  0.3056243855234042\n",
            "115 - Perda do treino:  1.0201351517341068 / Perda da validação:  0.305211677284751\n",
            "116 - Perda do treino:  1.020046678350584 / Perda da validação:  0.3048005510365958\n",
            "117 - Perda do treino:  1.0199587603392177 / Perda da validação:  0.30439100007500997\n",
            "118 - Perda do treino:  1.0198713941924695 / Perda da validação:  0.3039830177276691\n",
            "119 - Perda do treino:  1.0197845764247746 / Perda da validação:  0.3035765973536898\n",
            "120 - Perda do treino:  1.019698303572406 / Perda da validação:  0.3031717323434671\n",
            "121 - Perda do treino:  1.01961257219334 / Perda da validação:  0.30276841611851346\n",
            "122 - Perda do treino:  1.0195273788671213 / Perda da validação:  0.3023666421312981\n",
            "123 - Perda do treino:  1.0194427201947287 / Perda da validação:  0.301966403865087\n",
            "124 - Perda do treino:  1.0193585927984443 / Perda da validação:  0.30156769483378454\n",
            "125 - Perda do treino:  1.01927499332172 / Perda da validação:  0.30117050858177563\n",
            "126 - Perda do treino:  1.0191919184290466 / Perda da validação:  0.3007748386837679\n",
            "127 - Perda do treino:  1.0191093648058238 / Perda da validação:  0.30038067874463653\n",
            "128 - Perda do treino:  1.0190273291582304 / Perda da validação:  0.2999880223992684\n",
            "129 - Perda do treino:  1.0189458082130958 / Perda da validação:  0.2995968633124076\n",
            "130 - Perda do treino:  1.018864798717772 / Perda da validação:  0.2992071951785015\n",
            "131 - Perda do treino:  1.0187842974400056 / Perda da validação:  0.2988190117215487\n",
            "132 - Perda do treino:  1.0187043011678134 / Perda da validação:  0.29843230669494647\n",
            "133 - Perda do treino:  1.0186248067093544 / Perda da validação:  0.29804707388134\n",
            "134 - Perda do treino:  1.0185458108928063 / Perda da validação:  0.29766330709247174\n",
            "135 - Perda do treino:  1.018467310566241 / Perda da validação:  0.2972810001690318\n",
            "136 - Perda do treino:  1.0183893025975015 / Perda da validação:  0.29690014698051015\n",
            "137 - Perda do treino:  1.0183117838740792 / Perda da validação:  0.29652074142504753\n",
            "138 - Perda do treino:  1.018234751302991 / Perda da validação:  0.2961427774292897\n",
            "139 - Perda do treino:  1.0181582018106607 / Perda da validação:  0.29576624894824005\n",
            "140 - Perda do treino:  1.018082132342796 / Perda da validação:  0.2953911499651149\n",
            "141 - Perda do treino:  1.0180065398642701 / Perda da validação:  0.29501747449119864\n",
            "142 - Perda do treino:  1.0179314213590025 / Perda da validação:  0.2946452165656998\n",
            "143 - Perda do treino:  1.0178567738298412 / Perda da validação:  0.2942743702556082\n",
            "144 - Perda do treino:  1.017782594298445 / Perda da validação:  0.29390492965555215\n",
            "145 - Perda do treino:  1.0177088798051663 / Perda da validação:  0.29353688888765755\n",
            "146 - Perda do treino:  1.0176356274089362 / Perda da validação:  0.29317024210140685\n",
            "147 - Perda do treino:  1.0175628341871477 / Perda da validação:  0.2928049834734992\n",
            "148 - Perda do treino:  1.017490497235542 / Perda da validação:  0.292441107207711\n",
            "149 - Perda do treino:  1.0174186136680947 / Perda da validação:  0.29207860753475756\n",
            "150 - Perda do treino:  1.0173471806169025 / Perda da validação:  0.2917174787121561\n",
            "151 - Perda do treino:  1.01727619523207 / Perda da validação:  0.2913577150240874\n",
            "152 - Perda do treino:  1.017205654681598 / Perda da validação:  0.29099931078126084\n",
            "153 - Perda do treino:  1.0171355561512736 / Perda da validação:  0.2906422603207785\n",
            "154 - Perda do treino:  1.0170658968445585 / Perda da validação:  0.2902865580060003\n",
            "155 - Perda do treino:  1.0169966739824785 / Perda da validação:  0.28993219822641025\n",
            "156 - Perda do treino:  1.0169278848035166 / Perda da validação:  0.2895791753974831\n",
            "157 - Perda do treino:  1.016859526563503 / Perda da validação:  0.2892274839605521\n",
            "158 - Perda do treino:  1.0167915965355072 / Perda da validação:  0.2888771183826765\n",
            "159 - Perda do treino:  1.016724092009731 / Perda da validação:  0.2885280731565115\n",
            "160 - Perda do treino:  1.0166570102934032 / Perda da validação:  0.2881803428001769\n",
            "161 - Perda do treino:  1.0165903487106716 / Perda da validação:  0.28783392185712825\n",
            "162 - Perda do treino:  1.0165241046025002 / Perda da validação:  0.287488804896027\n",
            "163 - Perda do treino:  1.0164582753265623 / Perda da validação:  0.28714498651061315\n",
            "164 - Perda do treino:  1.0163928582571393 / Perda da validação:  0.2868024613195773\n",
            "165 - Perda do treino:  1.016327850785014 / Perda da validação:  0.28646122396643364\n",
            "166 - Perda do treino:  1.0162632503173714 / Perda da validação:  0.2861212691193942\n",
            "167 - Perda do treino:  1.0161990542776942 / Perda da validação:  0.28578259147124285\n",
            "168 - Perda do treino:  1.016135260105663 / Perda da validação:  0.28544518573921096\n",
            "169 - Perda do treino:  1.0160718652570546 / Perda da validação:  0.28510904666485326\n",
            "170 - Perda do treino:  1.0160088672036423 / Perda da validação:  0.28477416901392394\n",
            "171 - Perda do treino:  1.0159462634330956 / Perda da validação:  0.28444054757625437\n",
            "172 - Perda do treino:  1.0158840514488827 / Perda da validação:  0.2841081771656308\n",
            "173 - Perda do treino:  1.0158222287701715 / Perda da validação:  0.28377705261967284\n",
            "174 - Perda do treino:  1.0157607929317307 / Perda da validação:  0.28344716879971293\n",
            "175 - Perda do treino:  1.0156997414838351 / Perda da validação:  0.28311852059067577\n",
            "176 - Perda do treino:  1.0156390719921669 / Perda da validação:  0.28279110290095966\n",
            "177 - Perda do treino:  1.0155787820377205 / Perda da validação:  0.2824649106623163\n",
            "178 - Perda do treino:  1.015518869216708 / Perda da validação:  0.28213993882973454\n",
            "179 - Perda do treino:  1.015459331140463 / Perda da validação:  0.2818161823813208\n",
            "180 - Perda do treino:  1.0154001654353475 / Perda da validação:  0.2814936363181835\n",
            "181 - Perda do treino:  1.0153413697426583 / Perda da validação:  0.2811722956643168\n",
            "182 - Perda do treino:  1.0152829417185327 / Perda da validação:  0.2808521554664839\n",
            "183 - Perda do treino:  1.0152248790338583 / Perda da validação:  0.280533210794103\n",
            "184 - Perda do treino:  1.0151671793741783 / Perda da validação:  0.28021545673913284\n",
            "185 - Perda do treino:  1.0151098404396033 / Perda da validação:  0.27989888841595845\n",
            "186 - Perda do treino:  1.0150528599447175 / Perda da validação:  0.27958350096127854\n",
            "187 - Perda do treino:  1.0149962356184907 / Perda da validação:  0.2792692895339925\n",
            "188 - Perda do treino:  1.0149399652041882 / Perda da validação:  0.27895624931508867\n",
            "189 - Perda do treino:  1.01488404645928 / Perda da validação:  0.27864437550753296\n",
            "190 - Perda do treino:  1.0148284771553553 / Perda da validação:  0.27833366333615867\n",
            "191 - Perda do treino:  1.0147732550780322 / Perda da validação:  0.27802410804755534\n",
            "192 - Perda do treino:  1.0147183780268705 / Perda da validação:  0.2777157049099601\n",
            "193 - Perda do treino:  1.0146638438152855 / Perda da validação:  0.27740844921314833\n",
            "194 - Perda do treino:  1.0146096502704613 / Perda da validação:  0.27710233626832537\n",
            "195 - Perda do treino:  1.0145557952332651 / Perda da validação:  0.27679736140801897\n",
            "196 - Perda do treino:  1.0145022765581608 / Perda da validação:  0.2764935199859718\n",
            "197 - Perda do treino:  1.0144490921131264 / Perda da validação:  0.2761908073770353\n",
            "198 - Perda do treino:  1.014396239779567 / Perda da validação:  0.2758892189770631\n",
            "199 - Perda do treino:  1.0143437174522334 / Perda da validação:  0.27558875020280577\n",
            "200 - Perda do treino:  1.0142915230391378 / Perda da validação:  0.27528939649180656\n",
            "201 - Perda do treino:  1.0142396544614702 / Perda da validação:  0.2749911533022961\n",
            "202 - Perda do treino:  1.0141881096535181 / Perda da validação:  0.27469401611308936\n",
            "203 - Perda do treino:  1.0141368865625833 / Perda da validação:  0.27439798042348224\n",
            "204 - Perda do treino:  1.014085983148901 / Perda da validação:  0.2741030417531486\n",
            "205 - Perda do treino:  1.0140353973855596 / Perda da validação:  0.2738091956420391\n",
            "206 - Perda do treino:  1.01398512725842 / Perda da validação:  0.27351643765027883\n",
            "207 - Perda do treino:  1.0139351707660356 / Perda da validação:  0.27322476335806645\n",
            "208 - Perda do treino:  1.0138855259195736 / Perda da validação:  0.2729341683655743\n",
            "209 - Perda do treino:  1.0138361907427365 / Perda da validação:  0.2726446482928478\n",
            "210 - Perda do treino:  1.0137871632716826 / Perda da validação:  0.2723561987797066\n",
            "211 - Perda do treino:  1.0137384415549495 / Perda da validação:  0.2720688154856457\n",
            "212 - Perda do treino:  1.013690023653376 / Perda da validação:  0.2717824940897369\n",
            "213 - Perda do treino:  1.013641907640026 / Perda da validação:  0.2714972302905312\n",
            "214 - Perda do treino:  1.0135940916001114 / Perda da validação:  0.27121301980596185\n",
            "215 - Perda do treino:  1.0135465736309166 / Perda da validação:  0.27092985837324723\n",
            "216 - Perda do treino:  1.0134993518417228 / Perda da validação:  0.27064774174879497\n",
            "217 - Perda do treino:  1.013452424353733 / Perda da validação:  0.27036666570810586\n",
            "218 - Perda do treino:  1.0134057892999988 / Perda da validação:  0.27008662604567923\n",
            "219 - Perda do treino:  1.0133594448253445 / Perda da validação:  0.269807618574918\n",
            "220 - Perda do treino:  1.0133133890862942 / Perda da validação:  0.26952963912803474\n",
            "221 - Perda do treino:  1.0132676202509991 / Perda da validação:  0.2692526835559578\n",
            "222 - Perda do treino:  1.0132221364991647 / Perda da validação:  0.2689767477282385\n",
            "223 - Perda do treino:  1.0131769360219782 / Perda da validação:  0.26870182753295807\n",
            "224 - Perda do treino:  1.013132017022037 / Perda da validação:  0.2684279188766362\n",
            "225 - Perda do treino:  1.013087377713277 / Perda da validação:  0.2681550176841386\n",
            "226 - Perda do treino:  1.0130430163209023 / Perda da validação:  0.26788311989858643\n",
            "227 - Perda do treino:  1.0129989310813148 / Perda da validação:  0.2676122214812658\n",
            "228 - Perda do treino:  1.0129551202420433 / Perda da validação:  0.26734231841153683\n",
            "229 - Perda do treino:  1.012911582061674 / Perda da validação:  0.26707340668674473\n",
            "230 - Perda do treino:  1.0128683148097832 / Perda da validação:  0.2668054823221305\n",
            "231 - Perda do treino:  1.0128253167668657 / Perda da validação:  0.2665385413507417\n",
            "232 - Perda do treino:  1.012782586224268 / Perda da validação:  0.26627257982334485\n",
            "233 - Perda do treino:  1.012740121484122 / Perda da validação:  0.2660075938083374\n",
            "234 - Perda do treino:  1.0126979208592737 / Perda da validação:  0.26574357939166016\n",
            "235 - Perda do treino:  1.0126559826732195 / Perda da validação:  0.26548053267671096\n",
            "236 - Perda do treino:  1.0126143052600385 / Perda da validação:  0.26521844978425807\n",
            "237 - Perda do treino:  1.0125728869643253 / Perda da validação:  0.26495732685235396\n",
            "238 - Perda do treino:  1.0125317261411257 / Perda da validação:  0.26469716003625093\n",
            "239 - Perda do treino:  1.0124908211558707 / Perda da validação:  0.2644379455083146\n",
            "240 - Perda do treino:  1.0124501703843107 / Perda da validação:  0.2641796794579405\n",
            "241 - Perda do treino:  1.0124097722124523 / Perda da validação:  0.26392235809146986\n",
            "242 - Perda do treino:  1.0123696250364929 / Perda da validação:  0.26366597763210553\n",
            "243 - Perda do treino:  1.0123297272627578 / Perda da validação:  0.26341053431982914\n",
            "244 - Perda do treino:  1.0122900773076364 / Perda da validação:  0.2631560244113183\n",
            "245 - Perda do treino:  1.0122506735975183 / Perda da validação:  0.2629024441798645\n",
            "246 - Perda do treino:  1.0122115145687327 / Perda da validação:  0.2626497899152906\n",
            "247 - Perda do treino:  1.0121725986674843 / Perda da validação:  0.2623980579238704\n",
            "248 - Perda do treino:  1.0121339243497922 / Perda da validação:  0.2621472445282466\n",
            "249 - Perda do treino:  1.0120954900814283 / Perda da validação:  0.26189734606735143\n",
            "250 - Perda do treino:  1.0120572943378565 / Perda da validação:  0.2616483588963254\n",
            "251 - Perda do treino:  1.0120193356041718 / Perda da validação:  0.2614002793864382\n",
            "252 - Perda do treino:  1.0119816123750391 / Perda da validação:  0.26115310392500957\n",
            "253 - Perda do treino:  1.0119441231546351 / Perda da validação:  0.26090682891533\n",
            "254 - Perda do treino:  1.0119068664565862 / Perda da validação:  0.26066145077658265\n",
            "255 - Perda do treino:  1.0118698408039126 / Perda da validação:  0.2604169659437651\n",
            "256 - Perda do treino:  1.0118330447289656 / Perda da validação:  0.2601733708676122\n",
            "257 - Perda do treino:  1.0117964767733723 / Perda da validação:  0.25993066201451825\n",
            "258 - Perda do treino:  1.0117601354879755 / Perda da validação:  0.2596888358664608\n",
            "259 - Perda do treino:  1.011724019432777 / Perda da validação:  0.2594478889209241\n",
            "260 - Perda do treino:  1.0116881271768796 / Perda da validação:  0.2592078176908228\n",
            "261 - Perda do treino:  1.0116524572984305 / Perda da validação:  0.2589686187044274\n",
            "262 - Perda do treino:  1.011617008384564 / Perda da validação:  0.2587302885052877\n",
            "263 - Perda do treino:  1.0115817790313453 / Perda da validação:  0.25849282365215936\n",
            "264 - Perda do treino:  1.0115467678437153 / Perda da validação:  0.2582562207189286\n",
            "265 - Perda do treino:  1.0115119734354332 / Perda da validação:  0.25802047629453917\n",
            "266 - Perda do treino:  1.0114773944290238 / Perda da validação:  0.25778558698291776\n",
            "267 - Perda do treino:  1.01144302945572 / Perda da validação:  0.25755154940290154\n",
            "268 - Perda do treino:  1.0114088771554088 / Perda da validação:  0.25731836018816534\n",
            "269 - Perda do treino:  1.0113749361765787 / Perda da validação:  0.257086015987149\n",
            "270 - Perda do treino:  1.0113412051762631 / Perda da validação:  0.25685451346298543\n",
            "271 - Perda do treino:  1.0113076828199887 / Perda da validação:  0.256623849293429\n",
            "272 - Perda do treino:  1.0112743677817213 / Perda da validação:  0.2563940201707848\n",
            "273 - Perda do treino:  1.011241258743813 / Perda da validação:  0.25616502280183673\n",
            "274 - Perda do treino:  1.0112083543969501 / Perda da validação:  0.25593685390777765\n",
            "275 - Perda do treino:  1.0111756534400995 / Perda da validação:  0.2557095102241397\n",
            "276 - Perda do treino:  1.011143154580458 / Perda da validação:  0.2554829885007236\n",
            "277 - Perda do treino:  1.0111108565334004 / Perda da validação:  0.2552572855015298\n",
            "278 - Perda do treino:  1.0110787580224272 / Perda da validação:  0.2550323980046897\n",
            "279 - Perda do treino:  1.0110468577791152 / Perda da validação:  0.25480832280239646\n",
            "280 - Perda do treino:  1.011015154543065 / Perda da validação:  0.25458505670083686\n",
            "281 - Perda do treino:  1.0109836470618525 / Perda da validação:  0.254362596520124\n",
            "282 - Perda do treino:  1.0109523340909772 / Perda da validação:  0.2541409390942287\n",
            "283 - Perda do treino:  1.0109212143938133 / Perda da validação:  0.25392008127091314\n",
            "284 - Perda do treino:  1.01089028674156 / Perda da validação:  0.25370001991166374\n",
            "285 - Perda do treino:  1.0108595499131923 / Perda da validação:  0.25348075189162456\n",
            "286 - Perda do treino:  1.0108290026954123 / Perda da validação:  0.2532622740995313\n",
            "287 - Perda do treino:  1.0107986438826009 / Perda da validação:  0.25304458343764547\n",
            "288 - Perda do treino:  1.010768472276769 / Perda da validação:  0.2528276768216887\n",
            "289 - Perda do treino:  1.0107384866875093 / Perda da validação:  0.25261155118077844\n",
            "290 - Perda do treino:  1.0107086859319507 / Perda da validação:  0.2523962034573622\n",
            "291 - Perda do treino:  1.0106790688347078 / Perda da validação:  0.25218163060715343\n",
            "292 - Perda do treino:  1.0106496342278366 / Perda da validação:  0.25196782959906816\n",
            "293 - Perda do treino:  1.0106203809507863 / Perda da validação:  0.25175479741516027\n",
            "294 - Perda do treino:  1.010591307850353 / Perda da validação:  0.2515425310505588\n",
            "295 - Perda do treino:  1.010562413780634 / Perda da validação:  0.2513310275134043\n",
            "296 - Perda do treino:  1.0105336976029813 / Perda da validação:  0.2511202838247867\n",
            "297 - Perda do treino:  1.0105051581859565 / Perda da validação:  0.2509102970186826\n",
            "298 - Perda do treino:  1.0104767944052857 / Perda da validação:  0.2507010641418931\n",
            "299 - Perda do treino:  1.0104486051438133 / Perda da validação:  0.25049258225398213\n",
            "300 - Perda do treino:  1.0104205892914586 / Perda da validação:  0.2502848484272152\n",
            "301 - Perda do treino:  1.0103927457451705 / Perda da validação:  0.25007785974649815\n",
            "302 - Perda do treino:  1.0103650734088827 / Perda da validação:  0.24987161330931631\n",
            "303 - Perda do treino:  1.0103375711934723 / Perda da validação:  0.24966610622567434\n",
            "304 - Perda do treino:  1.0103102380167133 / Perda da validação:  0.24946133561803557\n",
            "305 - Perda do treino:  1.0102830728032342 / Perda da validação:  0.24925729862126275\n",
            "306 - Perda do treino:  1.0102560744844755 / Perda da validação:  0.2490539923825581\n",
            "307 - Perda do treino:  1.0102292419986463 / Perda da validação:  0.24885141406140449\n",
            "308 - Perda do treino:  1.0102025742906817 / Perda da validação:  0.24864956082950607\n",
            "309 - Perda do treino:  1.0101760703122007 / Perda da validação:  0.24844842987073026\n",
            "310 - Perda do treino:  1.0101497290214638 / Perda da validação:  0.248248018381049\n",
            "311 - Perda do treino:  1.0101235493833318 / Perda da validação:  0.24804832356848108\n",
            "312 - Perda do treino:  1.0100975303692237 / Perda da validação:  0.2478493426530343\n",
            "313 - Perda do treino:  1.0100716709570756 / Perda da validação:  0.24765107286664834\n",
            "314 - Perda do treino:  1.0100459701313 / Perda da validação:  0.24745351145313738\n",
            "315 - Perda do treino:  1.0100204268827446 / Perda da validação:  0.24725665566813362\n",
            "316 - Perda do treino:  1.009995040208652 / Perda da validação:  0.2470605027790307\n",
            "317 - Perda do treino:  1.0099698091126192 / Perda da validação:  0.24686505006492748\n",
            "318 - Perda do treino:  1.0099447326045585 / Perda da validação:  0.24667029481657235\n",
            "319 - Perda do treino:  1.0099198097006563 / Perda da validação:  0.24647623433630747\n",
            "320 - Perda do treino:  1.0098950394233348 / Perda da validação:  0.2462828659380135\n",
            "321 - Perda do treino:  1.0098704208012124 / Perda da validação:  0.24609018694705495\n",
            "322 - Perda do treino:  1.0098459528690644 / Perda da validação:  0.24589819470022473\n",
            "323 - Perda do treino:  1.0098216346677842 / Perda da validação:  0.2457068865456903\n",
            "324 - Perda do treino:  1.0097974652443455 / Perda da validação:  0.24551625984293962\n",
            "325 - Perda do treino:  1.0097734436517638 / Perda da validação:  0.2453263119627267\n",
            "326 - Perda do treino:  1.0097495689490568 / Perda da validação:  0.24513704028701871\n",
            "327 - Perda do treino:  1.009725840201209 / Perda da validação:  0.24494844220894216\n",
            "328 - Perda do treino:  1.0097022564791331 / Perda da validação:  0.24476051513273006\n",
            "329 - Perda do treino:  1.0096788168596311 / Perda da validação:  0.24457325647366918\n",
            "330 - Perda do treino:  1.0096555204253606 / Perda da validação:  0.24438666365804776\n",
            "331 - Perda do treino:  1.0096323662647946 / Perda da validação:  0.2442007341231028\n",
            "332 - Perda do treino:  1.0096093534721866 / Perda da validação:  0.2440154653169687\n",
            "333 - Perda do treino:  1.0095864811475337 / Perda da validação:  0.24383085469862548\n",
            "334 - Perda do treino:  1.0095637483965407 / Perda da validação:  0.2436468997378471\n",
            "335 - Perda do treino:  1.0095411543305843 / Perda da validação:  0.2434635979151505\n",
            "336 - Perda do treino:  1.0095186980666764 / Perda da validação:  0.24328094672174494\n",
            "337 - Perda do treino:  1.009496378727429 / Perda da validação:  0.2430989436594811\n",
            "338 - Perda do treino:  1.0094741954410194 / Perda da validação:  0.24291758624080106\n",
            "339 - Perda do treino:  1.0094521473411553 / Perda da validação:  0.24273687198868793\n",
            "340 - Perda do treino:  1.0094302335670384 / Perda da validação:  0.24255679843661643\n",
            "341 - Perda do treino:  1.0094084532633323 / Perda da validação:  0.24237736312850272\n",
            "342 - Perda do treino:  1.0093868055801252 / Perda da validação:  0.24219856361865594\n",
            "343 - Perda do treino:  1.0093652896728975 / Perda da validação:  0.24202039747172838\n",
            "344 - Perda do treino:  1.009343904702488 / Perda da validação:  0.24184286226266738\n",
            "345 - Perda do treino:  1.0093226498350587 / Perda da validação:  0.2416659555766664\n",
            "346 - Perda do treino:  1.0093015242420624 / Perda da validação:  0.2414896750091166\n",
            "347 - Perda do treino:  1.0092805271002092 / Perda da validação:  0.24131401816555945\n",
            "348 - Perda do treino:  1.0092596575914325 / Perda da validação:  0.2411389826616383\n",
            "349 - Perda do treino:  1.0092389149028576 / Perda da validação:  0.24096456612305114\n",
            "350 - Perda do treino:  1.009218298226767 / Perda da validação:  0.2407907661855035\n",
            "351 - Perda do treino:  1.0091978067605696 / Perda da validação:  0.24061758049466092\n",
            "352 - Perda do treino:  1.0091774397067677 / Perda da validação:  0.24044500670610264\n",
            "353 - Perda do treino:  1.0091571962729247 / Perda da validação:  0.24027304248527476\n",
            "354 - Perda do treino:  1.009137075671633 / Perda da validação:  0.2401016855074441\n",
            "355 - Perda do treino:  1.0091170771204834 / Perda da validação:  0.23993093345765218\n",
            "356 - Perda do treino:  1.0090971998420317 / Perda da validação:  0.2397607840306689\n",
            "357 - Perda do treino:  1.009077443063769 / Perda da validação:  0.23959123493094775\n",
            "358 - Perda do treino:  1.0090578060180906 / Perda da validação:  0.23942228387257974\n",
            "359 - Perda do treino:  1.009038287942263 / Perda da validação:  0.23925392857924846\n",
            "360 - Perda do treino:  1.0090188880783963 / Perda da validação:  0.23908616678418557\n",
            "361 - Perda do treino:  1.0089996056734105 / Perda da validação:  0.23891899623012564\n",
            "362 - Perda do treino:  1.0089804399790072 / Perda da validação:  0.23875241466926198\n",
            "363 - Perda do treino:  1.008961390251639 / Perda da validação:  0.23858641986320223\n",
            "364 - Perda do treino:  1.008942455752479 / Perda da validação:  0.23842100958292473\n",
            "365 - Perda do treino:  1.0089236357473914 / Perda da validação:  0.23825618160873444\n",
            "366 - Perda do treino:  1.0089049295069015 / Perda da validação:  0.23809193373021964\n",
            "367 - Perda do treino:  1.0088863363061673 / Perda da validação:  0.2379282637462084\n",
            "368 - Perda do treino:  1.0088678554249486 / Perda da validação:  0.23776516946472576\n",
            "369 - Perda do treino:  1.00884948614758 / Perda da validação:  0.2376026487029507\n",
            "370 - Perda do treino:  1.0088312277629399 / Perda da validação:  0.2374406992871736\n",
            "371 - Perda do treino:  1.0088130795644232 / Perda da validação:  0.23727931905275373\n",
            "372 - Perda do treino:  1.0087950408499124 / Perda da validação:  0.237118505844077\n",
            "373 - Perda do treino:  1.0087771109217494 / Perda da validação:  0.23695825751451438\n",
            "374 - Perda do treino:  1.0087592890867063 / Perda da validação:  0.2367985719263796\n",
            "375 - Perda do treino:  1.0087415746559596 / Perda da validação:  0.23663944695088773\n",
            "376 - Perda do treino:  1.00872396694506 / Perda da validação:  0.23648088046811422\n",
            "377 - Perda do treino:  1.0087064652739066 / Perda da validação:  0.23632287036695332\n",
            "378 - Perda do treino:  1.0086890689667183 / Perda da validação:  0.2361654145450774\n",
            "379 - Perda do treino:  1.0086717773520069 / Perda da validação:  0.2360085109088962\n",
            "380 - Perda do treino:  1.00865458976255 / Perda da validação:  0.2358521573735163\n",
            "381 - Perda do treino:  1.0086375055353638 / Perda da validação:  0.23569635186270074\n",
            "382 - Perda do treino:  1.008620524011677 / Perda da validação:  0.2355410923088291\n",
            "383 - Perda do treino:  1.0086036445369035 / Perda da validação:  0.23538637665285772\n",
            "384 - Perda do treino:  1.0085868664606161 / Perda da validação:  0.23523220284427954\n",
            "385 - Perda do treino:  1.0085701891365206 / Perda da validação:  0.23507856884108538\n",
            "386 - Perda do treino:  1.0085536119224288 / Perda da validação:  0.23492547260972377\n",
            "387 - Perda do treino:  1.0085371341802332 / Perda da validação:  0.23477291212506263\n",
            "388 - Perda do treino:  1.0085207552758824 / Perda da validação:  0.2346208853703501\n",
            "389 - Perda do treino:  1.0085044745793523 / Perda da validação:  0.23446939033717581\n",
            "390 - Perda do treino:  1.0084882914646236 / Perda da validação:  0.23431842502543257\n",
            "391 - Perda do treino:  1.0084722053096555 / Perda da validação:  0.23416798744327783\n",
            "392 - Perda do treino:  1.00845621549636 / Perda da validação:  0.2340180756070959\n",
            "393 - Perda do treino:  1.008440321410578 / Perda da validação:  0.2338686875414599\n",
            "394 - Perda do treino:  1.0084245224420532 / Perda da validação:  0.233719821279094\n",
            "395 - Perda do treino:  1.0084088179844086 / Perda da validação:  0.23357147486083618\n",
            "396 - Perda do treino:  1.008393207435121 / Perda da validação:  0.2334236463356006\n",
            "397 - Perda do treino:  1.0083776901954973 / Perda da validação:  0.2332763337603406\n",
            "398 - Perda do treino:  1.0083622656706501 / Perda da validação:  0.23312953520001187\n",
            "399 - Perda do treino:  1.0083469332694737 / Perda da validação:  0.23298324872753548\n",
            "400 - Perda do treino:  1.0083316924046197 / Perda da validação:  0.23283747242376154\n",
            "401 - Perda do treino:  1.0083165424924743 / Perda da validação:  0.2326922043774328\n",
            "402 - Perda do treino:  1.008301482953133 / Perda da validação:  0.23254744268514824\n",
            "403 - Perda do treino:  1.0082865132103789 / Perda da validação:  0.23240318545132718\n",
            "404 - Perda do treino:  1.0082716326916585 / Perda da validação:  0.23225943078817365\n",
            "405 - Perda do treino:  1.0082568408280586 / Perda da validação:  0.23211617681564056\n",
            "406 - Perda do treino:  1.008242137054283 / Perda da validação:  0.2319734216613941\n",
            "407 - Perda do treino:  1.0082275208086302 / Perda da validação:  0.23183116346077895\n",
            "408 - Perda do treino:  1.0082129915329705 / Perda da validação:  0.23168940035678243\n",
            "409 - Perda do treino:  1.0081985486727234 / Perda da validação:  0.23154813050000023\n",
            "410 - Perda do treino:  1.0081841916768342 / Perda da validação:  0.23140735204860138\n",
            "411 - Perda do treino:  1.0081699199977536 / Perda da validação:  0.23126706316829373\n",
            "412 - Perda do treino:  1.0081557330914137 / Perda da validação:  0.23112726203228956\n",
            "413 - Perda do treino:  1.008141630417207 / Perda da validação:  0.2309879468212713\n",
            "414 - Perda do treino:  1.008127611437964 / Perda da validação:  0.23084911572335742\n",
            "415 - Perda do treino:  1.008113675619932 / Perda da validação:  0.23071076693406883\n",
            "416 - Perda do treino:  1.008099822432753 / Perda da validação:  0.23057289865629488\n",
            "417 - Perda do treino:  1.0080860513494423 / Perda da validação:  0.23043550910025998\n",
            "418 - Perda do treino:  1.0080723618463672 / Perda da validação:  0.2302985964834901\n",
            "419 - Perda do treino:  1.0080587534032257 / Perda da validação:  0.23016215903077963\n",
            "420 - Perda do treino:  1.0080452255030252 / Perda da validação:  0.23002619497415852\n",
            "421 - Perda do treino:  1.0080317776320626 / Perda da validação:  0.2298907025528591\n",
            "422 - Perda do treino:  1.0080184092799023 / Perda da validação:  0.22975568001328361\n",
            "423 - Perda do treino:  1.0080051199393558 / Perda da validação:  0.22962112560897152\n",
            "424 - Perda do treino:  1.0079919091064615 / Perda da validação:  0.22948703760056738\n",
            "425 - Perda do treino:  1.0079787762804637 / Perda da validação:  0.22935341425578826\n",
            "426 - Perda do treino:  1.007965720963793 / Perda da validação:  0.22922025384939199\n",
            "427 - Perda do treino:  1.0079527426620458 / Perda da validação:  0.2290875546631451\n",
            "428 - Perda do treino:  1.0079398408839637 / Perda da validação:  0.22895531498579139\n",
            "429 - Perda do treino:  1.0079270151414148 / Perda da validação:  0.22882353311301987\n",
            "430 - Perda do treino:  1.0079142649493726 / Perda da validação:  0.22869220734743378\n",
            "431 - Perda do treino:  1.0079015898258974 / Perda da validação:  0.2285613359985193\n",
            "432 - Perda do treino:  1.0078889892921157 / Perda da validação:  0.228430917382614\n",
            "433 - Perda do treino:  1.007876462872202 / Perda da validação:  0.2283009498228767\n",
            "434 - Perda do treino:  1.0078640100933582 / Perda da validação:  0.2281714316492557\n",
            "435 - Perda do treino:  1.007851630485796 / Perda da validação:  0.22804236119845914\n",
            "436 - Perda do treino:  1.0078393235827157 / Perda da validação:  0.22791373681392377\n",
            "437 - Perda do treino:  1.0078270889202894 / Perda da validação:  0.22778555684578503\n",
            "438 - Perda do treino:  1.007814926037641 / Perda da validação:  0.22765781965084683\n",
            "439 - Perda do treino:  1.0078028344768275 / Perda da validação:  0.22753052359255124\n",
            "440 - Perda do treino:  1.0077908137828209 / Perda da validação:  0.22740366704094916\n",
            "441 - Perda do treino:  1.0077788635034894 / Perda da validação:  0.2272772483726701\n",
            "442 - Perda do treino:  1.0077669831895792 / Perda da validação:  0.2271512659708928\n",
            "443 - Perda do treino:  1.0077551723946965 / Perda da validação:  0.22702571822531575\n",
            "444 - Perda do treino:  1.0077434306752882 / Perda da validação:  0.22690060353212815\n",
            "445 - Perda do treino:  1.0077317575906253 / Perda da validação:  0.22677592029398044\n",
            "446 - Perda do treino:  1.0077201527027848 / Perda da validação:  0.2266516669199555\n",
            "447 - Perda do treino:  1.0077086155766313 / Perda da validação:  0.2265278418255397\n",
            "448 - Perda do treino:  1.0076971457797996 / Perda da validação:  0.22640444343259433\n",
            "449 - Perda do treino:  1.0076857428826769 / Perda da validação:  0.22628147016932704\n",
            "450 - Perda do treino:  1.007674406458386 / Perda da validação:  0.22615892047026326\n",
            "451 - Perda do treino:  1.0076631360827677 / Perda da validação:  0.22603679277621805\n",
            "452 - Perda do treino:  1.0076519313343628 / Perda da validação:  0.22591508553426803\n",
            "453 - Perda do treino:  1.0076407917943961 / Perda da validação:  0.2257937971977233\n",
            "454 - Perda do treino:  1.0076297170467592 / Perda da validação:  0.22567292622609955\n",
            "455 - Perda do treino:  1.007618706677993 / Perda da validação:  0.22555247108509052\n",
            "456 - Perda do treino:  1.0076077602772702 / Perda da validação:  0.2254324302465401\n",
            "457 - Perda do treino:  1.0075968774363815 / Perda da validação:  0.22531280218841526\n",
            "458 - Perda do treino:  1.007586057749716 / Perda da validação:  0.22519358539477854\n",
            "459 - Perda do treino:  1.007575300814246 / Perda da validação:  0.2250747783557609\n",
            "460 - Perda do treino:  1.0075646062295105 / Perda da validação:  0.22495637956753473\n",
            "461 - Perda do treino:  1.0075539735975991 / Perda da validação:  0.2248383875322868\n",
            "462 - Perda do treino:  1.0075434025231347 / Perda da validação:  0.22472080075819187\n",
            "463 - Perda do treino:  1.0075328926132598 / Perda da validação:  0.2246036177593857\n",
            "464 - Perda do treino:  1.0075224434776178 / Perda da validação:  0.22448683705593858\n",
            "465 - Perda do treino:  1.0075120547283394 / Perda da validação:  0.22437045717382906\n",
            "466 - Perda do treino:  1.007501725980025 / Perda da validação:  0.22425447664491777\n",
            "467 - Perda do treino:  1.00749145684973 / Perda da validação:  0.2241388940069211\n",
            "468 - Perda do treino:  1.0074812469569498 / Perda da validação:  0.22402370780338554\n",
            "469 - Perda do treino:  1.0074710959236026 / Perda da validação:  0.2239089165836614\n",
            "470 - Perda do treino:  1.0074610033740155 / Perda da validação:  0.22379451890287766\n",
            "471 - Perda do treino:  1.0074509689349092 / Perda da validação:  0.22368051332191558\n",
            "472 - Perda do treino:  1.0074409922353815 / Perda da validação:  0.2235668984073839\n",
            "473 - Perda do treino:  1.0074310729068938 / Perda da validação:  0.22345367273159328\n",
            "474 - Perda do treino:  1.0074212105832547 / Perda da validação:  0.22334083487253106\n",
            "475 - Perda do treino:  1.0074114049006067 / Perda da validação:  0.22322838341383627\n",
            "476 - Perda do treino:  1.0074016554974095 / Perda da validação:  0.2231163169447743\n",
            "477 - Perda do treino:  1.0073919620144272 / Perda da validação:  0.22300463406021245\n",
            "478 - Perda do treino:  1.007382324094712 / Perda da validação:  0.22289333336059514\n",
            "479 - Perda do treino:  1.0073727413835907 / Perda da validação:  0.22278241345191904\n",
            "480 - Perda do treino:  1.00736321352865 / Perda da validação:  0.22267187294570895\n",
            "481 - Perda do treino:  1.0073537401797226 / Perda da validação:  0.22256171045899292\n",
            "482 - Perda do treino:  1.007344320988872 / Perda da validação:  0.22245192461427882\n",
            "483 - Perda do treino:  1.0073349556103783 / Perda da validação:  0.22234251403952926\n",
            "484 - Perda do treino:  1.0073256437007263 / Perda da validação:  0.2222334773681383\n",
            "485 - Perda do treino:  1.0073163849185882 / Perda da validação:  0.22212481323890718\n",
            "486 - Perda do treino:  1.0073071789248118 / Perda da validação:  0.2220165202960207\n",
            "487 - Perda do treino:  1.0072980253824073 / Perda da validação:  0.22190859718902356\n",
            "488 - Perda do treino:  1.0072889239565317 / Perda da validação:  0.2218010425727967\n",
            "489 - Perda do treino:  1.0072798743144757 / Perda da validação:  0.22169385510753425\n",
            "490 - Perda do treino:  1.007270876125651 / Perda da validação:  0.22158703345871938\n",
            "491 - Perda do treino:  1.0072619290615767 / Perda da validação:  0.22148057629710202\n",
            "492 - Perda do treino:  1.0072530327958644 / Perda da validação:  0.22137448229867546\n",
            "493 - Perda do treino:  1.007244187004207 / Perda da validação:  0.22126875014465303\n",
            "494 - Perda do treino:  1.0072353913643641 / Perda da validação:  0.22116337852144582\n",
            "495 - Perda do treino:  1.0072266455561496 / Perda da validação:  0.22105836612063956\n",
            "496 - Perda do treino:  1.0072179492614175 / Perda da validação:  0.22095371163897193\n",
            "497 - Perda do treino:  1.0072093021640514 / Perda da validação:  0.22084941377831013\n",
            "498 - Perda do treino:  1.0072007039499489 / Perda da validação:  0.22074547124562885\n",
            "499 - Perda do treino:  1.0071921543070093 / Perda da validação:  0.22064188275298718\n",
            "500 - Perda do treino:  1.007183652925123 / Perda da validação:  0.2205386470175072\n",
            "501 - Perda do treino:  1.0071751994961564 / Perda da validação:  0.2204357627613514\n",
            "502 - Perda do treino:  1.0071667937139408 / Perda da validação:  0.22033322871170063\n",
            "503 - Perda do treino:  1.007158435274259 / Perda da validação:  0.22023104360073273\n",
            "504 - Perda do treino:  1.0071501238748337 / Perda da validação:  0.22012920616560025\n",
            "505 - Perda do treino:  1.007141859215314 / Perda da validação:  0.22002771514840905\n",
            "506 - Perda do treino:  1.0071336409972655 / Perda da validação:  0.2199265692961967\n",
            "507 - Perda do treino:  1.007125468924155 / Perda da validação:  0.2198257673609109\n",
            "508 - Perda do treino:  1.0071173427013413 / Perda da validação:  0.21972530809938845\n",
            "509 - Perda do treino:  1.0071092620360607 / Perda da validação:  0.2196251902733335\n",
            "510 - Perda do treino:  1.007101226637417 / Perda da validação:  0.21952541264929684\n",
            "511 - Perda do treino:  1.0070932362163691 / Perda da validação:  0.21942597399865474\n",
            "512 - Perda do treino:  1.0070852904857184 / Perda da validação:  0.21932687309758792\n",
            "513 - Perda do treino:  1.0070773891600981 / Perda da validação:  0.21922810872706075\n",
            "514 - Perda do treino:  1.007069531955961 / Perda da validação:  0.21912967967280048\n",
            "515 - Perda do treino:  1.0070617185915682 / Perda da validação:  0.21903158472527692\n",
            "516 - Perda do treino:  1.0070539487869774 / Perda da validação:  0.2189338226796813\n",
            "517 - Perda do treino:  1.007046222264032 / Perda da validação:  0.21883639233590638\n",
            "518 - Perda do treino:  1.007038538746348 / Perda da validação:  0.2187392924985258\n",
            "519 - Perda do treino:  1.0070308979593066 / Perda da validação:  0.21864252197677397\n",
            "520 - Perda do treino:  1.0070232996300377 / Perda da validação:  0.21854607958452585\n",
            "521 - Perda do treino:  1.007015743487413 / Perda da validação:  0.218449964140277\n",
            "522 - Perda do treino:  1.0070082292620337 / Perda da validação:  0.21835417446712366\n",
            "523 - Perda do treino:  1.0070007566862187 / Perda da validação:  0.2182587093927426\n",
            "524 - Perda do treino:  1.006993325493994 / Perda da validação:  0.2181635677493717\n",
            "525 - Perda do treino:  1.006985935421083 / Perda da validação:  0.21806874837379026\n",
            "526 - Perda do treino:  1.006978586204894 / Perda da validação:  0.21797425010729912\n",
            "527 - Perda do treino:  1.0069712775845105 / Perda da validação:  0.2178800717957015\n",
            "528 - Perda do treino:  1.0069640093006813 / Perda da validação:  0.21778621228928358\n",
            "529 - Perda do treino:  1.006956781095807 / Perda da validação:  0.21769267044279497\n",
            "530 - Perda do treino:  1.0069495927139336 / Perda da validação:  0.21759944511543\n",
            "531 - Perda do treino:  1.0069424439007384 / Perda da validação:  0.217506535170808\n",
            "532 - Perda do treino:  1.0069353344035217 / Perda da validação:  0.2174139394769547\n",
            "533 - Perda do treino:  1.0069282639711958 / Perda da validação:  0.2173216569062833\n",
            "534 - Perda do treino:  1.0069212323542753 / Perda da validação:  0.21722968633557552\n",
            "535 - Perda do treino:  1.006914239304866 / Perda da validação:  0.21713802664596282\n",
            "536 - Perda do treino:  1.0069072845766551 / Perda da validação:  0.21704667672290792\n",
            "537 - Perda do treino:  1.0069003679249016 / Perda da validação:  0.21695563545618596\n",
            "538 - Perda do treino:  1.0068934891064263 / Perda da validação:  0.21686490173986642\n",
            "539 - Perda do treino:  1.0068866478796008 / Perda da validação:  0.21677447447229445\n",
            "540 - Perda do treino:  1.0068798440043392 / Perda da validação:  0.2166843525560728\n",
            "541 - Perda do treino:  1.0068730772420869 / Perda da validação:  0.21659453489804306\n",
            "542 - Perda do treino:  1.0068663473558117 / Perda da validação:  0.2165050204092684\n",
            "543 - Perda do treino:  1.006859654109994 / Perda da validação:  0.2164158080050147\n",
            "544 - Perda do treino:  1.0068529972706166 / Perda da validação:  0.2163268966047333\n",
            "545 - Perda do treino:  1.006846376605156 / Perda da validação:  0.21623828513204274\n",
            "546 - Perda do treino:  1.006839791882573 / Perda da validação:  0.2161499725147109\n",
            "547 - Perda do treino:  1.0068332428733016 / Perda da validação:  0.21606195768463773\n",
            "548 - Perda do treino:  1.0068267293492412 / Perda da validação:  0.21597423957783707\n",
            "549 - Perda do treino:  1.006820251083747 / Perda da validação:  0.21588681713441962\n",
            "550 - Perda do treino:  1.0068138078516211 / Perda da validação:  0.21579968929857546\n",
            "551 - Perda do treino:  1.0068073994291016 / Perda da validação:  0.21571285501855625\n",
            "552 - Perda do treino:  1.0068010255938558 / Perda da validação:  0.21562631324665843\n",
            "553 - Perda do treino:  1.006794686124969 / Perda da validação:  0.21554006293920577\n",
            "554 - Perda do treino:  1.0067883808029374 / Perda da validação:  0.2154541030565324\n",
            "555 - Perda do treino:  1.0067821094096576 / Perda da validação:  0.21536843256296562\n",
            "556 - Perda do treino:  1.0067758717284179 / Perda da validação:  0.21528305042680915\n",
            "557 - Perda do treino:  1.0067696675438904 / Perda da validação:  0.21519795562032612\n",
            "558 - Perda do treino:  1.0067634966421217 / Perda da validação:  0.21511314711972235\n",
            "559 - Perda do treino:  1.0067573588105234 / Perda da validação:  0.21502862390512942\n",
            "560 - Perda do treino:  1.006751253837864 / Perda da validação:  0.2149443849605884\n",
            "561 - Perda do treino:  1.0067451815142614 / Perda da validação:  0.21486042927403326\n",
            "562 - Perda do treino:  1.0067391416311722 / Perda da validação:  0.2147767558372738\n",
            "563 - Perda do treino:  1.0067331339813848 / Perda da validação:  0.21469336364598018\n",
            "564 - Perda do treino:  1.0067271583590094 / Perda da validação:  0.2146102516996659\n",
            "565 - Perda do treino:  1.0067212145594715 / Perda da validação:  0.21452741900167172\n",
            "566 - Perda do treino:  1.0067153023795026 / Perda da validação:  0.21444486455914963\n",
            "567 - Perda do treino:  1.0067094216171308 / Perda da validação:  0.2143625873830469\n",
            "568 - Perda do treino:  1.0067035720716748 / Perda da validação:  0.21428058648808962\n",
            "569 - Perda do treino:  1.0066977535437336 / Perda da validação:  0.21419886089276702\n",
            "570 - Perda do treino:  1.0066919658351798 / Perda da validação:  0.21411740961931555\n",
            "571 - Perda do treino:  1.0066862087491502 / Perda da validação:  0.2140362316937034\n",
            "572 - Perda do treino:  1.0066804820900388 / Perda da validação:  0.21395532614561427\n",
            "573 - Perda do treino:  1.0066747856634888 / Perda da validação:  0.21387469200843207\n",
            "574 - Perda do treino:  1.0066691192763841 / Perda da validação:  0.2137943283192251\n",
            "575 - Perda do treino:  1.0066634827368413 / Perda da validação:  0.21371423411873108\n",
            "576 - Perda do treino:  1.0066578758542026 / Perda da validação:  0.2136344084513409\n",
            "577 - Perda do treino:  1.006652298439027 / Perda da validação:  0.21355485036508415\n",
            "578 - Perda do treino:  1.0066467503030838 / Perda da validação:  0.21347555891161324\n",
            "579 - Perda do treino:  1.0066412312593433 / Perda da validação:  0.21339653314618837\n",
            "580 - Perda do treino:  1.0066357411219713 / Perda da validação:  0.2133177721276626\n",
            "581 - Perda do treino:  1.0066302797063185 / Perda da validação:  0.2132392749184663\n",
            "582 - Perda do treino:  1.0066248468289167 / Perda da validação:  0.21316104058459273\n",
            "583 - Perda do treino:  1.0066194423074677 / Perda da validação:  0.21308306819558281\n",
            "584 - Perda do treino:  1.006614065960838 / Perda da validação:  0.21300535682451022\n",
            "585 - Perda do treino:  1.0066087176090508 / Perda da validação:  0.21292790554796676\n",
            "586 - Perda do treino:  1.0066033970732788 / Perda da validação:  0.2128507134460476\n",
            "587 - Perda do treino:  1.0065981041758365 / Perda da validação:  0.21277377960233665\n",
            "588 - Perda do treino:  1.0065928387401728 / Perda da validação:  0.21269710310389192\n",
            "589 - Perda do treino:  1.0065876005908645 / Perda da validação:  0.21262068304123088\n",
            "590 - Perda do treino:  1.0065823895536092 / Perda da validação:  0.21254451850831663\n",
            "591 - Perda do treino:  1.0065772054552167 / Perda da validação:  0.21246860860254255\n",
            "592 - Perda do treino:  1.0065720481236036 / Perda da validação:  0.212392952424719\n",
            "593 - Perda do treino:  1.0065669173877851 / Perda da validação:  0.21231754907905837\n",
            "594 - Perda do treino:  1.0065618130778688 / Perda da validação:  0.21224239767316105\n",
            "595 - Perda do treino:  1.0065567350250473 / Perda da validação:  0.21216749731800172\n",
            "596 - Perda do treino:  1.0065516830615917 / Perda da validação:  0.21209284712791474\n",
            "597 - Perda do treino:  1.0065466570208437 / Perda da validação:  0.2120184462205807\n",
            "598 - Perda do treino:  1.0065416567372103 / Perda da validação:  0.21194429371701196\n",
            "599 - Perda do treino:  1.0065366820461552 / Perda da validação:  0.21187038874153927\n",
            "600 - Perda do treino:  1.006531732784194 / Perda da validação:  0.21179673042179786\n",
            "601 - Perda do treino:  1.0065268087888866 / Perda da validação:  0.2117233178887136\n",
            "602 - Perda do treino:  1.0065219098988294 / Perda da validação:  0.2116501502764893\n",
            "603 - Perda do treino:  1.0065170359536513 / Perda da validação:  0.2115772267225915\n",
            "604 - Perda do treino:  1.0065121867940046 / Perda da validação:  0.2115045463677366\n",
            "605 - Perda do treino:  1.00650736226156 / Perda da validação:  0.21143210835587728\n",
            "606 - Perda do treino:  1.006502562198999 / Perda da validação:  0.21135991183418948\n",
            "607 - Perda do treino:  1.006497786450009 / Perda da validação:  0.21128795595305894\n",
            "608 - Perda do treino:  1.0064930348592755 / Perda da validação:  0.21121623986606758\n",
            "609 - Perda do treino:  1.0064883072724762 / Perda da validação:  0.21114476272998087\n",
            "610 - Perda do treino:  1.0064836035362745 / Perda da validação:  0.21107352370473423\n",
            "611 - Perda do treino:  1.0064789234983142 / Perda da validação:  0.2110025219534198\n",
            "612 - Perda do treino:  1.006474267007211 / Perda da validação:  0.21093175664227415\n",
            "613 - Perda do treino:  1.0064696339125496 / Perda da validação:  0.2108612269406644\n",
            "614 - Perda do treino:  1.0064650240648745 / Perda da validação:  0.2107909320210759\n",
            "615 - Perda do treino:  1.0064604373156847 / Perda da validação:  0.21072087105909917\n",
            "616 - Perda do treino:  1.0064558735174294 / Perda da validação:  0.21065104323341716\n",
            "617 - Perda do treino:  1.0064513325234994 / Perda da validação:  0.21058144772579251\n",
            "618 - Perda do treino:  1.0064468141882226 / Perda da validação:  0.21051208372105465\n",
            "619 - Perda do treino:  1.006442318366858 / Perda da validação:  0.21044295040708758\n",
            "620 - Perda do treino:  1.0064378449155889 / Perda da validação:  0.21037404697481693\n",
            "621 - Perda do treino:  1.0064333936915169 / Perda da validação:  0.21030537261819776\n",
            "622 - Perda do treino:  1.0064289645526587 / Perda da validação:  0.21023692653420176\n",
            "623 - Perda do treino:  1.0064245573579365 / Perda da validação:  0.21016870792280534\n",
            "624 - Perda do treino:  1.0064201719671744 / Perda da validação:  0.21010071598697677\n",
            "625 - Perda do treino:  1.0064158082410923 / Perda da validação:  0.21003294993266422\n",
            "626 - Perda do treino:  1.0064114660413006 / Perda da validação:  0.20996540896878363\n",
            "627 - Perda do treino:  1.0064071452302932 / Perda da validação:  0.20989809230720619\n",
            "628 - Perda do treino:  1.006402845671443 / Perda da validação:  0.2098309991627465\n",
            "629 - Perda do treino:  1.006398567228996 / Perda da validação:  0.20976412875315048\n",
            "630 - Perda do treino:  1.006394309768066 / Perda da validação:  0.20969748029908314\n",
            "631 - Perda do treino:  1.0063900731546283 / Perda da validação:  0.20963105302411714\n",
            "632 - Perda do treino:  1.0063858572555158 / Perda da validação:  0.20956484615472024\n",
            "633 - Perda do treino:  1.0063816619384107 / Perda da validação:  0.209498858920244\n",
            "634 - Perda do treino:  1.0063774870718423 / Perda da validação:  0.20943309055291182\n",
            "635 - Perda do treino:  1.006373332525179 / Perda da validação:  0.20936754028780716\n",
            "636 - Perda do treino:  1.0063691981686254 / Perda da validação:  0.2093022073628618\n",
            "637 - Perda do treino:  1.006365083873214 / Perda da validação:  0.2092370910188445\n",
            "638 - Perda do treino:  1.006360989510803 / Perda da validação:  0.20917219049934904\n",
            "639 - Perda do treino:  1.006356914954069 / Perda da validação:  0.20910750505078318\n",
            "640 - Perda do treino:  1.0063528600765026 / Perda da validação:  0.20904303392235662\n",
            "641 - Perda do treino:  1.006348824752402 / Perda da validação:  0.20897877636607012\n",
            "642 - Perda do treino:  1.0063448088568698 / Perda da validação:  0.20891473163670393\n",
            "643 - Perda do treino:  1.0063408122658073 / Perda da validação:  0.2088508989918063\n",
            "644 - Perda do treino:  1.0063368348559076 / Perda da validação:  0.2087872776916825\n",
            "645 - Perda do treino:  1.0063328765046538 / Perda da validação:  0.20872386699938367\n",
            "646 - Perda do treino:  1.0063289370903097 / Perda da validação:  0.20866066618069498\n",
            "647 - Perda do treino:  1.0063250164919195 / Perda da validação:  0.20859767450412572\n",
            "648 - Perda do treino:  1.0063211145892992 / Perda da validação:  0.20853489124089702\n",
            "649 - Perda do treino:  1.006317231263034 / Perda da validação:  0.20847231566493182\n",
            "650 - Perda do treino:  1.0063133663944712 / Perda da validação:  0.20840994705284316\n",
            "651 - Perda do treino:  1.006309519865718 / Perda da validação:  0.20834778468392381\n",
            "652 - Perda do treino:  1.006305691559634 / Perda da validação:  0.20828582784013508\n",
            "653 - Perda do treino:  1.0063018813598281 / Perda da validação:  0.2082240758060963\n",
            "654 - Perda do treino:  1.0062980891506537 / Perda da validação:  0.2081625278690738\n",
            "655 - Perda do treino:  1.0062943148172028 / Perda da validação:  0.20810118331897046\n",
            "656 - Perda do treino:  1.006290558245302 / Perda da validação:  0.20804004144831456\n",
            "657 - Perda do treino:  1.0062868193215082 / Perda da validação:  0.2079791015522498\n",
            "658 - Perda do treino:  1.006283097933103 / Perda da validação:  0.20791836292852445\n",
            "659 - Perda do treino:  1.0062793939680894 / Perda da validação:  0.20785782487748078\n",
            "660 - Perda do treino:  1.006275707315186 / Perda da validação:  0.20779748670204454\n",
            "661 - Perda do treino:  1.0062720378638224 / Perda da validação:  0.20773734770771463\n",
            "662 - Perda do treino:  1.0062683855041359 / Perda da validação:  0.2076774072025529\n",
            "663 - Perda do treino:  1.0062647501269653 / Perda da validação:  0.2076176644971735\n",
            "664 - Perda do treino:  1.0062611316238481 / Perda da validação:  0.20755811890473286\n",
            "665 - Perda do treino:  1.0062575298870151 / Perda da validação:  0.20749876974091905\n",
            "666 - Perda do treino:  1.006253944809386 / Perda da validação:  0.2074396163239424\n",
            "667 - Perda do treino:  1.006250376284564 / Perda da validação:  0.20738065797452418\n",
            "668 - Perda do treino:  1.0062468242068352 / Perda da validação:  0.2073218940158878\n",
            "669 - Perda do treino:  1.006243288471159 / Perda da validação:  0.20726332377374765\n",
            "670 - Perda do treino:  1.0062397689731681 / Perda da validação:  0.20720494657629968\n",
            "671 - Perda do treino:  1.006236265609162 / Perda da validação:  0.20714676175421146\n",
            "672 - Perda do treino:  1.0062327782761027 / Perda da validação:  0.20708876864061185\n",
            "673 - Perda do treino:  1.0062293068716117 / Perda da validação:  0.20703096657108153\n",
            "674 - Perda do treino:  1.0062258512939652 / Perda da validação:  0.20697335488364307\n",
            "675 - Perda do treino:  1.0062224114420895 / Perda da validação:  0.2069159329187508\n",
            "676 - Perda do treino:  1.0062189872155571 / Perda da validação:  0.2068587000192818\n",
            "677 - Perda do treino:  1.0062155785145825 / Perda da validação:  0.20680165553052543\n",
            "678 - Perda do treino:  1.0062121852400199 / Perda da validação:  0.20674479880017405\n",
            "679 - Perda do treino:  1.006208807293355 / Perda da validação:  0.20668812917831345\n",
            "680 - Perda do treino:  1.0062054445767052 / Perda da validação:  0.20663164601741313\n",
            "681 - Perda do treino:  1.0062020969928136 / Perda da validação:  0.20657534867231683\n",
            "682 - Perda do treino:  1.0061987644450447 / Perda da validação:  0.20651923650023307\n",
            "683 - Perda do treino:  1.006195446837381 / Perda da validação:  0.20646330886072567\n",
            "684 - Perda do treino:  1.00619214407442 / Perda da validação:  0.20640756511570424\n",
            "685 - Perda do treino:  1.0061888560613677 / Perda da validação:  0.20635200462941508\n",
            "686 - Perda do treino:  1.0061855827040378 / Perda da validação:  0.20629662676843158\n",
            "687 - Perda do treino:  1.0061823239088454 / Perda da validação:  0.20624143090164537\n",
            "688 - Perda do treino:  1.0061790795828045 / Perda da validação:  0.20618641640025648\n",
            "689 - Perda do treino:  1.0061758496335242 / Perda da validação:  0.20613158263776454\n",
            "690 - Perda do treino:  1.0061726339692032 / Perda da validação:  0.20607692898995955\n",
            "691 - Perda do treino:  1.0061694324986286 / Perda da validação:  0.2060224548349129\n",
            "692 - Perda do treino:  1.0061662451311704 / Perda da validação:  0.20596815955296793\n",
            "693 - Perda do treino:  1.0061630717767778 / Perda da validação:  0.20591404252673132\n",
            "694 - Perda do treino:  1.0061599123459763 / Perda da validação:  0.2058601031410637\n",
            "695 - Perda do treino:  1.006156766749864 / Perda da validação:  0.20580634078307108\n",
            "696 - Perda do treino:  1.0061536349001072 / Perda da validação:  0.20575275484209582\n",
            "697 - Perda do treino:  1.006150516708937 / Perda da validação:  0.20569934470970747\n",
            "698 - Perda do treino:  1.0061474120891465 / Perda da validação:  0.20564610977969414\n",
            "699 - Perda do treino:  1.006144320954086 / Perda da validação:  0.205593049448054\n",
            "700 - Perda do treino:  1.0061412432176595 / Perda da validação:  0.20554016311298612\n",
            "701 - Perda do treino:  1.0061381787943238 / Perda da validação:  0.20548745017488163\n",
            "702 - Perda do treino:  1.00613512759908 / Perda da validação:  0.2054349100363156\n",
            "703 - Perda do treino:  1.0061320895474752 / Perda da validação:  0.20538254210203793\n",
            "704 - Perda do treino:  1.0061290645555956 / Perda da validação:  0.20533034577896497\n",
            "705 - Perda do treino:  1.0061260525400644 / Perda da validação:  0.20527832047617078\n",
            "706 - Perda do treino:  1.006123053418038 / Perda da validação:  0.20522646560487884\n",
            "707 - Perda do treino:  1.0061200671072026 / Perda da validação:  0.20517478057845326\n",
            "708 - Perda do treino:  1.0061170935257713 / Perda da validação:  0.20512326481239068\n",
            "709 - Perda do treino:  1.0061141325924803 / Perda da validação:  0.2050719177243115\n",
            "710 - Perda do treino:  1.0061111842265855 / Perda da validação:  0.20502073873395169\n",
            "711 - Perda do treino:  1.006108248347859 / Perda da validação:  0.2049697272631545\n",
            "712 - Perda do treino:  1.0061053248765865 / Perda da validação:  0.20491888273586198\n",
            "713 - Perda do treino:  1.006102413733564 / Perda da validação:  0.2048682045781069\n",
            "714 - Perda do treino:  1.006099514840093 / Perda da validação:  0.2048176922180042\n",
            "715 - Perda do treino:  1.0060966281179797 / Perda da validação:  0.2047673450857433\n",
            "716 - Perda do treino:  1.0060937534895298 / Perda da validação:  0.20471716261357958\n",
            "717 - Perda do treino:  1.0060908908775463 / Perda da validação:  0.2046671442358261\n",
            "718 - Perda do treino:  1.0060880402053258 / Perda da validação:  0.20461728938884613\n",
            "719 - Perda do treino:  1.0060852013966557 / Perda da validação:  0.2045675975110442\n",
            "720 - Perda do treino:  1.0060823743758114 / Perda da validação:  0.20451806804285896\n",
            "721 - Perda do treino:  1.0060795590675518 / Perda da validação:  0.20446870042675477\n",
            "722 - Perda do treino:  1.0060767553971182 / Perda da validação:  0.20441949410721358\n",
            "723 - Perda do treino:  1.0060739632902294 / Perda da validação:  0.20437044853072744\n",
            "724 - Perda do treino:  1.00607118267308 / Perda da validação:  0.20432156314579034\n",
            "725 - Perda do treino:  1.0060684134723359 / Perda da validação:  0.2042728374028903\n",
            "726 - Perda do treino:  1.0060656556151337 / Perda da validação:  0.2042242707545019\n",
            "727 - Perda do treino:  1.0060629090290742 / Perda da validação:  0.20417586265507812\n",
            "728 - Perda do treino:  1.0060601736422234 / Perda da validação:  0.2041276125610429\n",
            "729 - Perda do treino:  1.0060574493831063 / Perda da validação:  0.20407951993078316\n",
            "730 - Perda do treino:  1.006054736180705 / Perda da validação:  0.20403158422464132\n",
            "731 - Perda do treino:  1.006052033964457 / Perda da validação:  0.2039838049049075\n",
            "732 - Perda do treino:  1.00604934266425 / Perda da validação:  0.2039361814358122\n",
            "733 - Perda do treino:  1.0060466622104218 / Perda da validação:  0.2038887132835184\n",
            "734 - Perda do treino:  1.0060439925337552 / Perda da validação:  0.20384139991611402\n",
            "735 - Perda do treino:  1.006041333565475 / Perda da validação:  0.2037942408036047\n",
            "736 - Perda do treino:  1.0060386852372474 / Perda da validação:  0.20374723541790604\n",
            "737 - Perda do treino:  1.0060360474811754 / Perda da validação:  0.20370038323283635\n",
            "738 - Perda do treino:  1.0060334202297958 / Perda da validação:  0.20365368372410889\n",
            "739 - Perda do treino:  1.006030803416078 / Perda da validação:  0.20360713636932504\n",
            "740 - Perda do treino:  1.00602819697342 / Perda da validação:  0.20356074064796661\n",
            "741 - Perda do treino:  1.006025600835645 / Perda da validação:  0.20351449604138824\n",
            "742 - Perda do treino:  1.0060230149370013 / Perda da validação:  0.20346840203281086\n",
            "743 - Perda do treino:  1.0060204392121572 / Perda da validação:  0.20342245810731363\n",
            "744 - Perda do treino:  1.0060178735961987 / Perda da validação:  0.20337666375182736\n",
            "745 - Perda do treino:  1.0060153180246272 / Perda da validação:  0.20333101845512683\n",
            "746 - Perda do treino:  1.006012772433357 / Perda da validação:  0.2032855217078239\n",
            "747 - Perda do treino:  1.0060102367587134 / Perda da validação:  0.20324017300236039\n",
            "748 - Perda do treino:  1.0060077109374272 / Perda da validação:  0.20319497183300078\n",
            "749 - Perda do treino:  1.0060051949066362 / Perda da validação:  0.2031499176958253\n",
            "750 - Perda do treino:  1.0060026886038784 / Perda da validação:  0.2031050100887229\n",
            "751 - Perda do treino:  1.0060001919670936 / Perda da validação:  0.2030602485113841\n",
            "752 - Perda do treino:  1.0059977049346172 / Perda da validação:  0.20301563246529436\n",
            "753 - Perda do treino:  1.005995227445179 / Perda da validação:  0.20297116145372632\n",
            "754 - Perda do treino:  1.005992759437903 / Perda da validação:  0.202926834981734\n",
            "755 - Perda do treino:  1.0059903008523006 / Perda da validação:  0.202882652556145\n",
            "756 - Perda do treino:  1.0059878516282705 / Perda da validação:  0.20283861368555414\n",
            "757 - Perda do treino:  1.0059854117060973 / Perda da validação:  0.2027947178803164\n",
            "758 - Perda do treino:  1.005982981026447 / Perda da validação:  0.20275096465254\n",
            "759 - Perda do treino:  1.005980559530365 / Perda da validação:  0.20270735351608016\n",
            "760 - Perda do treino:  1.0059781471592744 / Perda da validação:  0.2026638839865317\n",
            "761 - Perda do treino:  1.0059757438549735 / Perda da validação:  0.20262055558122283\n",
            "762 - Perda do treino:  1.0059733495596321 / Perda da validação:  0.20257736781920813\n",
            "763 - Perda do treino:  1.0059709642157912 / Perda da validação:  0.202534320221262\n",
            "764 - Perda do treino:  1.0059685877663587 / Perda da validação:  0.20249141230987214\n",
            "765 - Perda do treino:  1.0059662201546082 / Perda da validação:  0.20244864360923276\n",
            "766 - Perda do treino:  1.0059638613241764 / Perda da validação:  0.20240601364523822\n",
            "767 - Perda do treino:  1.0059615112190605 / Perda da validação:  0.2023635219454763\n",
            "768 - Perda do treino:  1.0059591697836168 / Perda da validação:  0.2023211680392218\n",
            "769 - Perda do treino:  1.0059568369625569 / Perda da validação:  0.2022789514574299\n",
            "770 - Perda do treino:  1.0059545127009464 / Perda da validação:  0.20223687173272978\n",
            "771 - Perda do treino:  1.0059521969442027 / Perda da validação:  0.2021949283994183\n",
            "772 - Perda do treino:  1.005949889638093 / Perda da validação:  0.2021531209934535\n",
            "773 - Perda do treino:  1.0059475907287305 / Perda da validação:  0.2021114490524482\n",
            "774 - Perda do treino:  1.0059453001625744 / Perda da validação:  0.20206991211566364\n",
            "775 - Perda do treino:  1.0059430178864255 / Perda da validação:  0.20202850972400302\n",
            "776 - Perda do treino:  1.0059407438474264 / Perda da validação:  0.2019872414200056\n",
            "777 - Perda do treino:  1.005938477993057 / Perda da validação:  0.20194610674784008\n",
            "778 - Perda do treino:  1.0059362202711335 / Perda da validação:  0.20190510525329847\n",
            "779 - Perda do treino:  1.0059339706298065 / Perda da validação:  0.20186423648378987\n",
            "780 - Perda do treino:  1.0059317290175578 / Perda da validação:  0.20182349998833415\n",
            "781 - Perda do treino:  1.0059294953832 / Perda da validação:  0.20178289531755605\n",
            "782 - Perda do treino:  1.0059272696758728 / Perda da validação:  0.20174242202367862\n",
            "783 - Perda do treino:  1.0059250518450404 / Perda da validação:  0.20170207966051779\n",
            "784 - Perda do treino:  1.0059228418404926 / Perda da validação:  0.20166186778347556\n",
            "785 - Perda do treino:  1.0059206396123386 / Perda da validação:  0.20162178594953423\n",
            "786 - Perda do treino:  1.0059184451110084 / Perda da validação:  0.2015818337172505\n",
            "787 - Perda do treino:  1.005916258287248 / Perda da validação:  0.20154201064674931\n",
            "788 - Perda do treino:  1.0059140790921202 / Perda da validação:  0.20150231629971768\n",
            "789 - Perda do treino:  1.0059119074769993 / Perda da validação:  0.20146275023939916\n",
            "790 - Perda do treino:  1.0059097433935724 / Perda da validação:  0.2014233120305875\n",
            "791 - Perda do treino:  1.005907586793835 / Perda da validação:  0.20138400123962108\n",
            "792 - Perda do treino:  1.00590543763009 / Perda da validação:  0.20134481743437682\n",
            "793 - Perda do treino:  1.0059032958549463 / Perda da validação:  0.2013057601842641\n",
            "794 - Perda do treino:  1.0059011614213145 / Perda da validação:  0.20126682906021953\n",
            "795 - Perda do treino:  1.0058990342824083 / Perda da validação:  0.20122802363470052\n",
            "796 - Perda do treino:  1.0058969143917404 / Perda da validação:  0.20118934348167988\n",
            "797 - Perda do treino:  1.005894801703121 / Perda da validação:  0.2011507881766399\n",
            "798 - Perda do treino:  1.005892696170656 / Perda da validação:  0.20111235729656643\n",
            "799 - Perda do treino:  1.005890597748745 / Perda da validação:  0.20107405041994375\n",
            "800 - Perda do treino:  1.005888506392079 / Perda da validação:  0.20103586712674826\n",
            "801 - Perda do treino:  1.0058864220556405 / Perda da validação:  0.20099780699844305\n",
            "802 - Perda do treino:  1.0058843446946988 / Perda da validação:  0.20095986961797224\n",
            "803 - Perda do treino:  1.0058822742648101 / Perda da validação:  0.20092205456975556\n",
            "804 - Perda do treino:  1.0058802107218152 / Perda da validação:  0.2008843614396823\n",
            "805 - Perda do treino:  1.0058781540218373 / Perda da validação:  0.20084678981510623\n",
            "806 - Perda do treino:  1.0058761041212807 / Perda da validação:  0.20080933928483966\n",
            "807 - Perda do treino:  1.0058740609768289 / Perda da validação:  0.20077200943914822\n",
            "808 - Perda do treino:  1.0058720245454424 / Perda da validação:  0.20073479986974493\n",
            "809 - Perda do treino:  1.0058699947843572 / Perda da validação:  0.20069771016978546\n",
            "810 - Perda do treino:  1.0058679716510834 / Perda da validação:  0.20066073993386171\n",
            "811 - Perda do treino:  1.005865955103403 / Perda da validação:  0.20062388875799725\n",
            "812 - Perda do treino:  1.005863945099368 / Perda da validação:  0.20058715623964138\n",
            "813 - Perda do treino:  1.0058619415972998 / Perda da validação:  0.20055054197766392\n",
            "814 - Perda do treino:  1.0058599445557852 / Perda da validação:  0.2005140455723497\n",
            "815 - Perda do treino:  1.0058579539336778 / Perda da validação:  0.20047766662539343\n",
            "816 - Perda do treino:  1.0058559696900928 / Perda da validação:  0.2004414047398944\n",
            "817 - Perda do treino:  1.005853991784409 / Perda da validação:  0.2004052595203507\n",
            "818 - Perda do treino:  1.0058520201762637 / Perda da validação:  0.20036923057265477\n",
            "819 - Perda do treino:  1.0058500548255538 / Perda da validação:  0.2003333175040872\n",
            "820 - Perda do treino:  1.005848095692432 / Perda da validação:  0.20029751992331218\n",
            "821 - Perda do treino:  1.0058461427373069 / Perda da validação:  0.20026183744037218\n",
            "822 - Perda do treino:  1.00584419592084 / Perda da validação:  0.20022626966668242\n",
            "823 - Perda do treino:  1.005842255203945 / Perda da validação:  0.20019081621502596\n",
            "824 - Perda do treino:  1.005840320547786 / Perda da validação:  0.20015547669954858\n",
            "825 - Perda do treino:  1.005838391913775 / Perda da validação:  0.20012025073575374\n",
            "826 - Perda do treino:  1.0058364692635717 / Perda da validação:  0.200085137940497\n",
            "827 - Perda do treino:  1.0058345525590813 / Perda da validação:  0.20005013793198137\n",
            "828 - Perda do treino:  1.0058326417624526 / Perda da validação:  0.20001525032975223\n",
            "829 - Perda do treino:  1.0058307368360766 / Perda da validação:  0.1999804747546921\n",
            "830 - Perda do treino:  1.005828837742586 / Perda da validação:  0.19994581082901572\n",
            "831 - Perda do treino:  1.0058269444448513 / Perda da validação:  0.19991125817626504\n",
            "832 - Perda do treino:  1.005825056905982 / Perda da validação:  0.19987681642130425\n",
            "833 - Perda do treino:  1.0058231750893234 / Perda da validação:  0.19984248519031467\n",
            "834 - Perda do treino:  1.0058212989584552 / Perda da validação:  0.19980826411079008\n",
            "835 - Perda do treino:  1.0058194284771906 / Perda da validação:  0.19977415281153155\n",
            "836 - Perda do treino:  1.0058175636095743 / Perda da validação:  0.19974015092264277\n",
            "837 - Perda do treino:  1.0058157043198814 / Perda da validação:  0.19970625807552497\n",
            "838 - Perda do treino:  1.005813850572616 / Perda da validação:  0.19967247390287213\n",
            "839 - Perda do treino:  1.0058120023325081 / Perda da validação:  0.19963879803866616\n",
            "840 - Perda do treino:  1.005810159564516 / Perda da validação:  0.1996052301181721\n",
            "841 - Perda do treino:  1.0058083222338194 / Perda da validação:  0.19957176977793326\n",
            "842 - Perda do treino:  1.0058064903058237 / Perda da validação:  0.19953841665576635\n",
            "843 - Perda do treino:  1.0058046637461544 / Perda da validação:  0.19950517039075705\n",
            "844 - Perda do treino:  1.0058028425206564 / Perda da validação:  0.19947203062325497\n",
            "845 - Perda do treino:  1.0058010265953954 / Perda da validação:  0.199438996994869\n",
            "846 - Perda do treino:  1.0057992159366527 / Perda da validação:  0.19940606914846257\n",
            "847 - Perda do treino:  1.0057974105109255 / Perda da validação:  0.19937324672814913\n",
            "848 - Perda do treino:  1.0057956102849264 / Perda da validação:  0.1993405293792873\n",
            "849 - Perda do treino:  1.0057938152255808 / Perda da validação:  0.19930791674847637\n",
            "850 - Perda do treino:  1.005792025300026 / Perda da validação:  0.19927540848355144\n",
            "851 - Perda do treino:  1.0057902404756092 / Perda da validação:  0.19924300423357913\n",
            "852 - Perda do treino:  1.0057884607198873 / Perda da validação:  0.19921070364885282\n",
            "853 - Perda do treino:  1.0057866860006244 / Perda da validação:  0.1991785063808881\n",
            "854 - Perda do treino:  1.0057849162857913 / Perda da validação:  0.19914641208241807\n",
            "855 - Perda do treino:  1.005783151543564 / Perda da validação:  0.1991144204073893\n",
            "856 - Perda do treino:  1.0057813917423226 / Perda da validação:  0.19908253101095663\n",
            "857 - Perda do treino:  1.0057796368506486 / Perda da validação:  0.19905074354947913\n",
            "858 - Perda do treino:  1.005777886837326 / Perda da validação:  0.19901905768051567\n",
            "859 - Perda do treino:  1.0057761416713369 / Perda da validação:  0.19898747306282\n",
            "860 - Perda do treino:  1.0057744013218641 / Perda da validação:  0.1989559893563369\n",
            "861 - Perda do treino:  1.0057726657582866 / Perda da validação:  0.19892460622219718\n",
            "862 - Perda do treino:  1.0057709349501796 / Perda da validação:  0.19889332332271392\n",
            "863 - Perda do treino:  1.0057692088673131 / Perda da validação:  0.19886214032137745\n",
            "864 - Perda do treino:  1.0057674874796507 / Perda da validação:  0.19883105688285135\n",
            "865 - Perda do treino:  1.0057657707573486 / Perda da validação:  0.19880007267296806\n",
            "866 - Perda do treino:  1.0057640586707541 / Perda da validação:  0.1987691873587244\n",
            "867 - Perda do treino:  1.0057623511904032 / Perda da validação:  0.19873840060827744\n",
            "868 - Perda do treino:  1.0057606482870232 / Perda da validação:  0.19870771209094001\n",
            "869 - Perda do treino:  1.0057589499315256 / Perda da validação:  0.1986771214771767\n",
            "870 - Perda do treino:  1.005757256095011 / Perda da validação:  0.19864662843859912\n",
            "871 - Perda do treino:  1.005755566748763 / Perda da validação:  0.19861623264796233\n",
            "872 - Perda do treino:  1.0057538818642506 / Perda da validação:  0.19858593377915987\n",
            "873 - Perda do treino:  1.0057522014131244 / Perda da validação:  0.19855573150722025\n",
            "874 - Perda do treino:  1.0057505253672172 / Perda da validação:  0.19852562550830205\n",
            "875 - Perda do treino:  1.005748853698542 / Perda da validação:  0.19849561545969052\n",
            "876 - Perda do treino:  1.0057471863792908 / Perda da validação:  0.19846570103979266\n",
            "877 - Perda do treino:  1.0057455233818344 / Perda da validação:  0.1984358819281335\n",
            "878 - Perda do treino:  1.0057438646787191 / Perda da validação:  0.19840615780535206\n",
            "879 - Perda do treino:  1.0057422102426687 / Perda da validação:  0.1983765283531969\n",
            "880 - Perda do treino:  1.005740560046581 / Perda da validação:  0.19834699325452226\n",
            "881 - Perda do treino:  1.0057389140635264 / Perda da validação:  0.198317552193284\n",
            "882 - Perda do treino:  1.0057372722667495 / Perda da validação:  0.1982882048545354\n",
            "Pausa na época 882 pois val_loss não melhorou por 30 épocas, o melhor valor de perda seria de 0.19921070364885282, na epoca 852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CONCLUSÃO**"
      ],
      "metadata": {
        "id": "Mj-rjNpaMxQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que a partir da época 852, a perda da validação não melhorou, e portanto depois de 30 épocas (definida pela paciência) o treino parou. Assim, a estratégia de Early Stopping foi implementada com sucesso, com o objetivo de evitar overfitting.\n",
        "\n",
        "Com esse notebook se aprendeu sobre early stop e também sobre o conceito de paciência, algo novo para os dois autores."
      ],
      "metadata": {
        "id": "mhKgHJKJM0iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **REFERÊNCIAS**"
      ],
      "metadata": {
        "id": "4PpW78iqJXxv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[1]** CASSAR, Daniel. Redes Neurais e Algoritmos Genéticos. 2025. Material de Aula.\n",
        "\n",
        "**[2]** KASHYAP, Piyush. Early Stopping in Deep Learning: A Simple Guide to Prevent Overfitting. Medium. 2021. Disponível em: https://medium.com/@piyushkashyap045/early-stopping-in-deep-learning-a-simple-guide-to-prevent-overfitting-1073f56b493e.\n",
        "\n",
        "**[3]** BROWNLEE, Jason. How to Stop Training Deep Neural Networks at the Right Time Using Early Stopping. Machine Learning Mastery. 2019. Disponível em: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/.\n",
        "\n",
        "**[4]** OLAMENDY, Juan C. Real World ML: Early Stopping in Deep Learning - A Comprehensive Guide. Medium. 2023. Disponível em: https://medium.com/@juanc.olamendy/real-world-ml-early-stopping-in-deep-learning-a-comprehensive-guide-fabb1e69f8cc."
      ],
      "metadata": {
        "id": "e7uugLL0KzFm"
      }
    }
  ]
}